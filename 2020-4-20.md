# WEB

## 基础

### osi

<table>
<thead>
<tr colspan="3">
<th colspan="1" style="text-align:left">层级</th>
<th colspan="1" style="text-align:center">主要协议</th>
<th colspan="1" style="text-align:center">交互格式</th>
<th colspan="1" style="text-align:center">负载均衡</th>
<th colspan="1" style="text-align:center">组件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">应用层</td>
<td style="text-align:center">HTTP(超文本)<br/>SMTP(邮件)<br/>DNS(域名)</td>
<td style="text-align:center">报文</td>
<td style="text-align:center">DNS负载均衡(延迟、缓存效应)<br/>反向代理(对服务器要求高,灵活)<br/>HTTP重定向(应用较少)</td>
<td style="text-align:center">WEB应用</td>
</tr>
<tr>
<td style="text-align:left">传输层</td>
<td style="text-align:center">TCP<br/>UDP</td>
<td style="text-align:center">数据段(TCP)<br/>数据报(UDP)</td>
<td style="text-align:center">虚拟IP</td>
<td style="text-align:center">四层交换机</td>
</tr>
<tr>
<td style="text-align:left">网络层</td>
<td style="text-align:center">IP</td>
<td style="text-align:center">数据包(IP包)</td>
<td style="text-align:center">直接路由<br/>NAT</td>
<td style="text-align:center">路由器</td>
</tr>
<tr>
<td style="text-align:left">链路层</td>
<td style="text-align:center">以太网<br/>帧中继等</td>
<td style="text-align:center">帧</td>
<td style="text-align:center">LVS(改mac地址)</td>
<td style="text-align:center">网卡<br/>网桥</td>
</tr>
<tr>
<td style="text-align:left">物理层</td>
<td style="text-align:center">X.21</td>
<td style="text-align:center">byte</td>
<td style="text-align:center"></td>
<td style="text-align:center">中继器<br/>集线器</td>
</tr>
</tbody>
</table>



### http

#### 三次握手四次挥手

<img src='./jNote/tcp.jpg'/>

#### 滑动窗口(流量控制)

<img src='./jNote/slipWindow.jpg'/>

#### 拥塞控制

cwnd:拥塞窗口(大小,起始值1)
ssthresh: 慢启动阈值(默认初始值)
慢开始算法: 先发送1字节试探,发送等比(每次RTT,cwnd=2*cwnd)字节
快恢复算法: 设置cwnd=ssthresh+ACK个数 *MSS
拥塞避免算法: 递增字节(每次RTT cwnd+1)发送

<img src='./jNote/ts.jpg'/>

<b>慢开始+拥塞控制算法</b>
发送方维护拥塞窗口大小,cwnd<ssthresh时,执行慢开始算法,cwnd>=ssthresh时执行拥塞避免算法
发现丢包后(对端接收到超序包(out-of-order)时会发送对失序包的重传请求)ssthresh=ssthresh/2; cwnd=1;

<b>快重传+快恢复</b>

发生丢包后,若连续接收到三个重复的重传请求(不等待重传计时器超时,立即重传),则cwnd = cwnd/2;sshthresh = cwnd;并执行拥塞避免算法; 若依然拥塞,则重复上过程

<img src='./jNote/ft.jpg'/>

#### TCP/UDP

- 最大传输单元MTU,受以太网和802.3数据帧限制,最大数据传输1500字节
  - 7字节前导同步码+1字节帧界定符+6字节目标MAC+6字节源MAC+2字节帧类型+1500+4字节校验
  - TCP要在1500字节中去掉20字节ip数据包包头、20字节TCP数据段包头[TCP消息头不含长度信息]
  - UDP要在1500中去掉8字节头信息(含长度信息)
- TCP定时器 TCP发送一组数据后会启动一个定时器,超时重传
- TCP分段 TCP在传输层被分成合适的段(不超过帧限制),但具体长度由三次握手商议决定
- TCP拆包,即一个TCP包被拆成多个发送
- TCP粘包,即多个TCP包被一次接收 [拆包/粘包是由于Nagle算法导致的]
- Nagle算法,即等待多次小消息填满socket缓冲区统一发送
- UDP-ip分片,DUP不进行分段,则UDP报大于MTU会导致ip分片[ip分片丢失会导致报文重传]
- ip分片重组,根据ip报头的3byte标志位(1保留,2标志分段,3标志是否是最后一段)和13位偏移量重组

#### 杂项

- SSL安全套接层在会话层
- 三次握手是为了确认客户端/服务端数据发送/接收能力正常的过程
- 拥塞控制是为了防止网络变差,流量控制是为了方便对方来得及接收,发送窗口为两者小值

### jvm

#### 内存模型

- java堆 大部分对象和数组都在此分配内存
- 方法区 类信息、常量、静态变量、即时编译后的代码
- 程序计数器  分支、跳转、循环依赖程序计数器
- 本地方法栈 本地方法的操作栈
- 虚拟机栈 主要包含 局部变量表、操作数栈、动态链接(指向方法区的方法)、方法返回地址
- 直接内存 不是虚拟机规定的, 但大部分NIO会实现

#### 加载过程

- 加载 加载流、转换为运行时数据结构、生成Class对象
- 验证 校验数据正确性
- 准备 分配内存、初始化默认值(不是初始值)
- 解析 类/接口解析、字段解析、类方法解析、接口方法解析
- 初始化 初始化初始值

#### New

- 初始化链条: 父类静态块,子类静态块,父类代码块,父类构造函数,子类代码块,子类构造函数
- 引用父类静态字段,不会导致父类初始化
- 创建对象方式: new、反射、clone、反序列化

#### 方法分派

java是一门静态多分派、动态单分派的语言

<img src='./jNote/dispatcherM.png'/>

#### 双亲加载机制

系统中含有四类类加载器, bootstrap类加载器负责加载lib/rt.jar extension类加载器负责加载lib/ext/*.jar,系统类加载器负责加载所有classpath上的类,自定义加载器; 双亲委托模型指当要加载一个类的时候, 会获取该类的全限定名, 然后委托双亲类加载器加载, 所谓委托双亲加载器加载即双亲在自己负责的路径中查找此限定名的类并加载; 虚拟机中的类是由加载器和类权限定名唯一确定的(自定义java.lang同名类无法被加载是因为同限定名的Class已经在虚拟机中存在了); 
违反双亲加载规则的场景 :

- SPI(Service Provider Interface, 类似于IOC): 当bootstrap或extension类加载器加载的类调用了用户代码情况(如JNDI, JDBC, JCE, JAXB, JBI), 即bootstrap或extension定义了接口, 但加载时要服务发现(加载实现类), 但实现类是个classpath上的类, bootstrap或extension都无法加载; 由此此时引入了线程上下文类加载器, 通过Thread的setContextClassLoader设置加载器, 如果未设置则默认使用系统类加载器
- 实现热插拔,热部署,模块化 : 为了添加/减去功能而不重启,只需把这模块连同类加载器一起替换掉

违反双亲加载规则实例 :tomcat(为了隔离webappClassLoader私有class未向其父类sharedClassLoader传递)

- 为了保证虚拟机中加载不同web项目中版本号不同的类各有一份
- 为了区分自己依赖的类库web项目依赖的类库
- 为了jsp热替换(jsp是编译成class的)

#### GC及调优

##### Base

- 引用:强、软(缓存)、弱(ThreadLocal)、虚(对象被收集器回收时收到一个系统通知)
- YGC 标记-复制
- CMS <img src='./jNote/cms.png'/>
- G1 G1首先对堆分块(1M~32M不等),对块在逻辑上分Eden、Survivor、Olden、Humongous(极大区域)

    - 基于分块的YGC可试STW时间可控在毫秒级  -XX:MaxGCPauseMillis

    - 并发度高 -XX:ParallelGCThreads

    - 空间整合好, 比CMS更不易产生空间碎片
- G1 YGC(young) 标记复制算法
- G1 MGC(mixed) 会触发一次YGC和<span style='color:red'>部分年老代对象[控制时间]</span>的收集(类似不含预处理的CMS,但清理过程STW,且可能触发疏散事件,即当前Old区占用过大,将部分疏散到其它块)
- G1 FGC(full) 当大对象分配过快,导致MGC来不及回收,会导致FGC,可认为FGC是单线程的Old GC, 尽量避免

##### 参数

<table>
<thead>
<tr colspan="3">
<th colspan="1" style="text-align:left">参数</th>
<th colspan="1" style="text-align:center">解释</th>
<th colspan="1" style="text-align:center">DEFAULT</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-Xms<br/>-Xmx</td>
<td style="text-align:center">初始/最大堆大小</td>
<td style="text-align:center">默认物理内存的1/64,1/4</td>
</tr>
<tr>
<td style="text-align:left">-Xmn</td>
<td style="text-align:center">新生代大小</td>
<td style="text-align:center">设置为堆大小的1/3或者1/4,年老代=堆大小-新生代大小</td>
</tr>
<tr>
<td style="text-align:left">-Xss</td>
<td style="text-align:center">线程内存大小</td>
<td style="text-align:center">一般1024K</td>
</tr>
<tr>
<td style="text-align:left">-XX:NewRatio</td>
<td style="text-align:center">新生代:年老代</td>
<td style="text-align:center">可由Xmn确定</td>
</tr>
<tr>
<td style="text-align:left">-XX:SurvivorRatio</td>
<td style="text-align:center">Eden区:Survivor区</td>
<td style="text-align:center">默认8:1:1,即-XX:SurvivorRatio=4</td>
</tr>
<tr>
<td style="text-align:left">-XX:InitialTenuringThreshold<br/>-XX:MaxTenuringThreshold</td>
<td style="text-align:center">新生代存活次数</td>
<td style="text-align:center">默认7/15</td>
</tr>
<tr>
<td style="text-align:left">-XX:PermSize<br/>-XX:MaxPermSize(7-)<br/>-XX:MetaspaceSize<br/>-XX:MaxMetaspaceSize(8+)</td>
<td style="text-align:center">永久代大小</td>
<td style="text-align:center">一般512M或256M</td>
</tr>
<tr>
<td style="text-align:left">-XX:+UseSerialGC<br/>-XX:+UseParallelGC</td>
<td style="text-align:center">设置串行收集器<br/>策略为新生代使用并行清除</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">-XX:+UseParalledlOldGC<br/>-XX:ParallelGCThreads=n<br/>-XX:MaxGCPauseMillis=n</td>
<td style="text-align:center">为老年代和新生代都使用并行清除的垃圾收集器<br/>设置收集器线程<br/>设置最大暂停时间</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">-XX:+UseConcMarkSweepGC<br/>-XX:ParallelGCThreads=n</td>
<td style="text-align:center">启用CMS低停顿垃圾收集器<br/>设置收集器线程</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">-XX:+PrintGC<br/>-XX:+PrintGCDetails<br/>-XX:+PrintGCTimeStamps</td>
<td style="text-align:center">GC日志</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>

- -Xms/-Xmx 一般设置为fullGC后年老代空间的3-4倍
- -XX:PermSize/-XX:MaxPermSize 一般设置为fullGC后永久代大小的1.2-1.5倍
- -Xmn 一般设置为fullGC后年老代的1-1.5倍
- 年老代 一般大小设置为fullGC后年老代的2-3倍,即堆大小设置为fullGC后年老代的3-4倍

##### 调优工具

jconsole jdk自带可视化监视平台

jvisualvm  jdk自带可视化监视平台,功能强大

jstat 语法: jstat [-param] \<pid\>  [时间间隔] [查询次数]        jstat -gcutil 4528 1000 30(每秒显示gc统计信息)
- -class 查询类加载情况[加载量|占用空间|未加载量|占用空间|用时]
- -compiler 编译统计信息[编译量|失败量|不可用|用时|失败类型|失败方法]
- -gc/-gccapacity 垃圾回收统计/堆内存统计
- -gcnew/-gcnewcapacity 新生代垃圾回收统计/堆内存统计
- -gcold/-gcoldcapacity  年老代垃圾回收统计/堆内存统计
- -gcutil 查看每个代区域使用的百分比情况
- -gccause 显示最近一次GC的原因
- -gcmetacapacity 元数据空间堆内存统计

jmap 语法:jmap [-param] \<pid\>  内存印象工具, 物理内存占用情况
- -dump:format=b,file=dump.bin 将内存占用情况输出到dump.bin文件
- -histo 内存对象信息 如:jmap -histo 4528 > a.log

jinfo 获取jvm运行参数 jinfo pid

jps -ml 获取java进程占用情况

jstack  堆栈信息,分析线程状态,可用来查询死锁  jstack pid

top 查询进程PID

top -Hp PID   显示线程TID

jstack PID |grep TID 获取线程程信息(TID要转义成16进制)

##### 性能调优

#### 1、Linux命令

##### 1.1 top命令



![img](https:////upload-images.jianshu.io/upload_images/4324380-ab8f965a6c991095.png?imageMogr2/auto-orient/strip|imageView2/2/w/967)

top命令


 top命令的输出可以分为上下两部分： **系统统计信息和进程统计信息。** 



**系统统计信息：**

- 第一行：任务队列信息。等同于**uptime命令**。

```css
20:30:40 up 71 days, 21:36,  1 user,  load average: 0.15, 0.16, 0.13
```

系统当前时间、系统运行时间、当前登录用户数。load average表示系统的平均负载（1分钟内、5分钟内、15分钟内）。

- 第二行：进程统计信息。分别为总的进程数、运行中的进程数、睡眠进程数、停止的进程数以及僵尸进程数。

- ```undefined
  Tasks:  75 total,   1 running,  74 sleeping,   0 stopped,   0 zombie
  ```

- 第三行：CPU统计信息。

```scss
Cpu(s):  0.4%us,  0.2%sy,  0.0%ni, 99.4%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
```

**us**:用户态CPU占用率、**sy**:内核态CPU占用率、**ni**:用户进程空间改变过优先级的进程CPU占用率、**id**:空闲CPU占用率、**wa**:等待输入输出的CPU时间百分比、**hi**:硬件中断请求、**si**:软件中断请求、**st**:CPU服务于软中断所耗费的时间总额。

- 第四行：内存统计信息。

```cpp
Mem:   1922244k total,  1200496k used,   721748k free,   181508k buffers
```

依次表示物理内存总量、已使用内存量、空闲内存量、内核缓冲使用量。

- 第五行：交换区统计信息。

```cpp
Swap:        0k total,        0k used,        0k free,   435204k cached
```

 依次表示交换区总量、已使用交互区总量、空闲交换区总量、缓冲的交换区总量。 

**进程统计信息：**

- PID：进程id
- USER：进程所有者的用户id
- PR：优先级
- NI：**nice值**。负值表示高优先级、正值表示低优先级
- VIRT：进程使用的虚拟内存总量。VIRT=SWAP+RES
- RES：进程使用的、未被换出的物理内存大小
- SHR：共享内存大小（KB）
- S：进程状态。R-运行、S-睡眠、D-不可中断的睡眠、T-跟踪/停止、Z-僵尸
- %CPU：上次更新到现在的CPU时间占用百分比
- %MEM：进程使用的物理内存百分比
- %TIME+：进程使用的CPU时间总计
- COMMAND：命令名

**top常用子命令：**

- h：帮助
- k：终止一个进程
- c：切换显示完整的命令行
- M：按照内存大小排序
- P：按照CPU占用百分比排序

##### 1.2 sar命令

sar命令也是Linux系统中重要的性能检测工具之一，可周期性的对内存和CPU的使用情况进行采样。如下：

```undefined
sar 1 5
```

**表示每隔1秒采样1次，共采样5次。**

```undefined
Linux 2.6.32-573.22.1.el6.x86_64 (-)    03/14/2017  _x86_64_    (1 CPU)

02:40:35 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
02:40:36 PM     all      0.99      0.00      0.99      0.00      0.00     98.02
02:40:37 PM     all      0.00      0.00      0.00      0.00      0.00    100.00
02:40:38 PM     all      1.00      0.00      0.00      0.00      0.00     99.00
02:40:39 PM     all      0.00      0.00      0.00      0.00      0.00    100.00
02:40:40 PM     all      0.00      0.00      0.00      0.00      0.00    100.00
Average:        all      0.40      0.00      0.20      0.00      0.00     99.40
```

**option选项：**

-A：所有报告。

-u：CPU利用率。默认选项。

-d：磁盘使用情况。

-b：I/O使用情况。

-q：查看队列长度。

-r：内存使用情况。

-n：查看网络信息统计。【ALL】

-o：将采样结果输出到文件

##### 1.3 vmstat命令

vmstat命令同样也是Linux系统中重要的性能检测工具之一，不仅可周期性的对内存、CPU进行采样，还可以对swap使用进行采样。

```undefined
vmstat 1 5
```

**表示每隔1秒采样一次，共采样5次。**

```objectivec
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 401032 183320 732700    0    0     3     2    3    6  0  0 99  0  0    
 0  0      0 401016 183320 732700    0    0     0     0  234  512  0  1 99  0  0    
 0  0      0 401016 183320 732700    0    0     0     0  220  495  0  0 100  0  0   
 0  0      0 401016 183320 732700    0    0     0    32  240  518  1  0 99  0  0    
 0  0      0 401016 183320 732700    0    0     0     0  244  511  0  0 100  0  0
```

procs

r：等待运行的进程数

b：处在非中断睡眠状态的进程数

memory

swpd：虚拟内存使用情况（KB）

free：空闲内存大小（KB）

buff：表示块设备(block device)所占用的缓存页，包括：直接读写块设备、以及文件系统元数据(metadata)，比如SuperBlock所使用的缓存页（KB）

cache：表示普通文件数据所占用的缓存页

swap

si：从磁盘交换到内存的交换页数量（KB/秒）

so：从内存交换到磁盘的交换页数量（KB/秒）

io

bi：发送到块设备的块数（块/秒）

bo：从块设备接收到的块数（块/秒）

system

in：每秒中断数

cs：每秒上下文切换次数

cpu

us：用户态CPU占用率

sy：内核态CPU占用率

id：空闲CPU占用率
 -wa：等待输入输出的CPU时间百分比

st：CPU服务于软中断所耗费的时间总额

##### 1.4 iostat命令

iostat可以提供详尽的I/O信息。

```undefined
iostat 1 2
```

- tps：该设备每秒的传输次数
- Blk_read/s：每秒从设备读取的数据量
- Blk_wrtn/s：每秒向设备写入的数据量
- Blk_read：读取的总数据量
- Blk_wrtn：写入的总数据量

##### 1.5 pidstat命令

pidstat也是一个功能强大的性能检测工具。不仅可以检测进程的性能，还可以检测线程的性能。

###### 1.5.1 CPU使用率监控

下面的程序中，开启了3个线程，其中一个大量占用CPU，其他2个线程处于空闲状态

```java
public class CPUMain {
    public static class BusyCPUTask implements Runnable {
        @Override
        public void run() {
            while (true) {
                double i = Math.random() * Math.random();
            }
        }
    }
    public static class LazyCPUTask implements Runnable {
        @Override
        public void run() {
            try {
                while (true) {
                    TimeUnit.SECONDS.sleep(1);
                }
            } catch (Exception e) {
                // do nothing
            }
        }
    }

    public static void main(String[] args) {
        new Thread(new BusyCPUTask()).start();
        new Thread(new LazyCPUTask()).start();
        new Thread(new LazyCPUTask()).start();
    }
}
```

 1、使用`jps -l`找到该Java程序的PID： 

```css
[root@- ~]# jps -l
19077 sun.tools.jps.Jps
19064 command.CPUMain
17338 org.elasticsearch.bootstrap.Elasticsearch
17851 org.jruby.Main
```

 2、使用`pidstat`命令输出该程序的CPU使用情况： 

```csharp
[root@- ~]# pidstat -p 19064 -u 1 3
Linux 2.6.32-573.22.1.el6.x86_64 (-)    03/14/2017  _x86_64_    (1 CPU)
05:49:01 PM       PID    %usr %system  %guest    %CPU   CPU  Command
05:49:02 PM     19064   99.00    0.00    0.00   99.00     0  java
05:49:03 PM     19064  100.00    0.00    0.00  100.00     0  java
05:49:04 PM     19064   99.00    0.00    0.00   99.00     0  java
Average:        19064   99.33    0.00    0.00   99.33     -  java
```

**-p \**指定进程的ID，\**-u \**对CPU使用率进行监控；\**每隔1秒采样1次，共采样3次。**

- 3、使用`-t`参数找出最占CPU的线程

```ruby
[root@- ~]# pidstat -p 19064  -u -t 1 1
Linux 2.6.32-573.22.1.el6.x86_64 (-)    03/14/2017  _x86_64_    (1 CPU)
05:56:00 PM      TGID       TID    %usr %system  %guest    %CPU   CPU  Command
05:56:01 PM     19064         -   99.00    0.00    0.00   99.00     0  java
05:56:01 PM         -     19064    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19065    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19066    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19067    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19068    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19069    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19070    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19071    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19072    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19073    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19074  100.00    0.00    0.00  100.00     0  |__java
05:56:01 PM         -     19075    0.00    0.00    0.00    0.00     0  |__java
05:56:01 PM         -     19076    0.00    0.00    0.00    0.00     0  |__java
```

 可以看到， **19074** 这个线程占用了大量CPU。
 **备注：上述2和3两个过程可以使用`top -p 19064 -H`命令查出哪个线程占用大量CPU，如下：** 

```css
[root@- ~]# top -p 19064 -H
top - 17:57:41 up 78 days, 19:03,  3 users,  load average: 1.00, 0.86, 0.55
Tasks:  13 total,   1 running,  12 sleeping,   0 stopped,   0 zombie
Cpu(s): 99.7%us,  0.3%sy,  0.0%ni,  0.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:   1922244k total,  1584308k used,   337936k free,   185344k buffers
Swap:        0k total,        0k used,        0k free,   776028k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                        
19064 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19065 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.07 java                                                                                                                            
19066 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19067 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19068 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19069 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19070 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19071 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19072 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java                                                                                                                            
19073 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.12 java                                                                                                                            
19074 root      20   0 2414m  23m  11m R 99.6  1.3   9:09.31 java                                                                                                                            
19075 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.01 java                                                                                                                            
19076 root      20   0 2414m  23m  11m S  0.0  1.3   0:00.00 java
```



得到的结果同样是**19074 **这个线程。

- 4、jstack定位线程栈
   `jstack 19064 > jstack.log` 
- 5、查看**19074**线程情况
   通过使用命令`printf %x 19074`得到**19074**的16进制：**4a82**
   查看**4a82**线程：

```bash
"Thread-0" #8 prio=5 os_prio=0 tid=0x00007fae380fa800 nid=0x4a82 runnable [0x00007fae3c551000]
   java.lang.Thread.State: RUNNABLE
        at command.CPUMain$BusyCPUTask.run(CPUMain.java:14)
        at java.lang.Thread.run(Thread.java:745)
```

**结论：**可以定位到线程在执行`CPUMain.java:14`占用了大量CPU。

###### 1.5.2 I/O监控

下面的程序中，开启了3个线程，其中一个大量占用I/O，其他2个线程处于空闲状态。

```java
public class IOMain {
    public static class BusyIOTask implements Runnable {
        @Override
        public void run() {
            try {
                FileOutputStream fos;
                FileInputStream fis;
                while (true) {
                    fos = new FileOutputStream(new File("temp"));
                    for (int i = 0; i < 1000; i++) {
                        fos.write(i);           // 写操作
                    }
                    fos.close();
                    fis = new FileInputStream(new File("temp"));
                    while (fis.read() != -1);   // 读操作
                    fis.close();
                }
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
```



```java
    public static class LazyIOTask implements Runnable {
        @Override
        public void run() {
            try {
                while (true) {
                    TimeUnit.SECONDS.sleep(1);
                }
            } catch (Exception e) {
                // do nothing
            }
        }
    }

    public static void main(String[] args) {
        new Thread(new IOMain.BusyIOTask()).start();
        new Thread(new IOMain.LazyIOTask()).start();
        new Thread(new IOMain.LazyIOTask()).start();
    }
}
```



 1、使用`jps -l`找到该Java程序的PID： 

```css
[root@- ~]# jps -l
17338 org.elasticsearch.bootstrap.Elasticsearch
17851 org.jruby.Main
19323 sun.tools.jps.Jps
19310 command.IOMain
```

 2、使用`pidstat`命令输出该程序的各个线程的I/O使用情况： 

```ruby
[root@- ~]# pidstat -p 19310 -d -t 1 3
Linux 2.6.32-573.22.1.el6.x86_64 (-)    03/14/2017  _x86_64_    (1 CPU)
06:30:13 PM      TGID       TID   kB_rd/s   kB_wr/s kB_ccwr/s  Command
06:30:14 PM     19310         -      0.00   3482.83   1741.41  java
06:30:14 PM         -     19310      0.00      0.00      0.00  |__java
06:30:14 PM         -     19311      0.00      0.00      0.00  |__java
06:30:14 PM         -     19312      0.00      0.00      0.00  |__java
06:30:14 PM         -     19313      0.00      0.00      0.00  |__java
06:30:14 PM         -     19314      0.00      0.00      0.00  |__java
06:30:14 PM         -     19315      0.00      0.00      0.00  |__java
06:30:14 PM         -     19316      0.00      0.00      0.00  |__java
06:30:14 PM         -     19317      0.00      0.00      0.00  |__java
06:30:14 PM         -     19318      0.00      0.00      0.00  |__java
06:30:14 PM         -     19319      0.00      0.00      0.00  |__java
06:30:14 PM         -     19320      0.00   3478.79   1741.41  |__java
06:30:14 PM         -     19321      0.00      0.00      0.00  |__java
06:30:14 PM         -     19322      0.00      0.00      0.00  |__java
... ...
```



- 3、定位线程栈
   同样地使用`jstack`命令，导出该程序的线程栈，查找**nid=19320(0x4b78)**的线程，即可定位问题。

###### 1.5.3 内存监控

使用`pidstat`命令，还可以监视指定进程的内存的使用情况。

使用`pidstat`命令，还可以监视指定进程的内存的使用情况。

```bash
[root@- test]# pidstat -p 17338 -r 1 3
Linux 2.6.32-573.22.1.el6.x86_64 (-)    03/14/2017  _x86_64_    (1 CPU)

06:36:36 PM       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command
06:36:37 PM     17338      0.00      0.00 2677708 280504  14.59  java
06:36:38 PM     17338      0.00      0.00 2677708 280504  14.59  java
06:36:39 PM     17338      0.00      0.00 2677708 280504  14.59  java
Average:        17338      0.00      0.00 2677708 280504  14.59  java
```



#### 2、JDK命令

##### 2.1 jps命令

jps命令类似于Linux的ps，只不过ps是查看Linux系统的进程，jps只是列出**当前用户启动的Java进程**。

- jps

```csharp
[root@- ~]# jps
17338 Elasticsearch
17851 Main
21166 Jps
```

- jps -q：只输出进程id
- jps -m：输出传递给Java Main函数的参数
- jps -l：输出Main函数的完整路径
- jps -v：输出传递给JVM的参数

##### 2.2 jstat命令

jstat命令用于观察Java程序的运行时工具。

```xml
Usage: jstat -help|-options
       jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]
```

**option可选项：**

- -class：显示ClassLoader的相关信息

```css
[root@- ~]# jstat -class -t 17338
Timestamp       Loaded  Bytes  Unloaded  Bytes     Time   
      4302040.9   8482 15664.4       12    12.0       7.94
```

Loaded表示载入类的数量、Bytes表示载入类的大小、Unloaded表示卸载类的数量、Bytes表示卸载类的大小、Time表示在加载及卸载类上所花的时间。**

- -compiler：显示JIT编译的相关信息

```css
[root@- ~]# jstat -compiler -t 17338
Timestamp       Compiled Failed Invalid   Time   FailedType FailedMethod
      4312097.9    12812      0       0    73.32          0
```

**Complied表示编译任务执行的次数、Failed表示编译失败的次数、Invalid表示不可用的次数、Time表示编译的总耗时、FailedType表示最后一次编译失败的类型、FailedMethod表示最后一次编译失败的类名和方法名。**

- -gc：显示与GC相关的堆信息

```css
[root@- ~]# jstat -gc -t 17338
Timestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   
      4312491.0 8512.0 8512.0  76.1   0.0   68160.0  15675.5   439104.0   18409.8   47780.0 47055.7 5600.0 5363.6    644    4.077   4      0.176    4.253
```

S1C：S1（To）的大小（KB）

S0U：S0（From）已使用的大小（KB）

S1U：S1（To）已使用的大小（KB）

EC：Eden区的大小（KB）

EU：Eden已使用的大小（KB）

OC：老年代大小（KB）

OU：老年代已使用的大小（KB）

MC：方法区大小（KB）

MU：方法区已使用大小（KB）

CCSC：压缩类空间大小（KB）

CCSU：压缩类空间已使用大小（KB）

PC：永久区大小（KB）

- PU：永久区已使用大小（KB）
- YGC：新生代GC次数
- YGCT：新生代GC耗时
- FGC：Full GC次数
- FGCT：Full GC耗时
- GCT：GC总耗时
- -gccapacity：显示各个代的容量及使用情况

```css
[root@- ~]# jstat -gccapacity -t 17338
Timestamp        NGCMN    NGCMX     NGC     S0C   S1C       EC      OGCMN      OGCMX       OGC         OC       MCMN     MCMX      MC     CCSMN    CCSMX     CCSC    YGC    FGC 
      4313185.9  85184.0  85184.0  85184.0 8512.0 8512.0  68160.0   439104.0   439104.0   439104.0   439104.0      0.0 1091584.0  47780.0      0.0 1048576.0   5600.0    644     4
```

与`-gc`相比，不仅输出了各个代当前的大小，还输出了各个代的最小、最大值。

- NGCMN：新生代最小值（KB）
- NGCMX：新生代最大值（KB）
- NGC：当前新生代大小（KB）
- OGCMN：老年代最小值（KB）
- OGCMX：老年代最大值（KB）
- PGCMN：永久区最小值（KB）
- PGCMX：永久区最大值（KB）
- -gccause：显示垃圾收集相关信息（同gcutil），同时显示最后一次或当前正在发生的垃圾收集的诱发原因

```css
[root@- ~]# jstat -gccause -t 17338
Timestamp         S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT    LGCC                 GCC                 
      4313692.2   0.89   0.00  43.07   4.19  98.48  95.78    644    4.077     4    0.176    4.253 Allocation Failure   No GC
```

- LGCC：最近一次GC的的原因
- GCC：当前GC的原因
- -gcnew：显示新生代信息

```css
[root@- ~]# jstat -gcnew -t 17338
Timestamp        S0C    S1C    S0U    S1U   TT MTT  DSS      EC       EU     YGC     YGCT  
      4314215.7 8512.0 8512.0   76.1    0.0  6   6 4256.0  68160.0  33355.0    644    4.077
```

- TT：新生代对象晋升到老年代对象的年龄
- MTT：新生代对象晋升到老年代对象的年龄最大值
- DSS：所需的幸存区大小
- -gcnewcapacity：显示新生代容量及使用情况

```css
[root@- ~]# jstat -gcnewcapacity -t 17338
Timestamp         NGCMN      NGCMX       NGC      S0CMX     S0C     S1CMX     S1C       ECMX        EC      YGC   FGC 
      4314357.1    85184.0    85184.0    85184.0   8512.0   8512.0   8512.0   8512.0    68160.0    68160.0   644     4
```

- S0CMX：S0区的最大值
- S1CMX：S1区的最大值
- ECMX：Eden区的最大值
- -gcold：显示老年代和永久代的信息

```css
[root@- ~]# jstat -gcold -t 17338
Timestamp          MC       MU      CCSC     CCSU       OC          OU       YGC    FGC    FGCT     GCT   
      4314463.2  47780.0  47055.7   5600.0   5363.6    439104.0     18409.8    644     4    0.176
```

 -gcoldcapacity：显示老年代容量 

```css
[root@- ~]# jstat -gcoldcapacity -t 17338
Timestamp          OGCMN       OGCMX        OGC         OC       YGC   FGC    FGCT     GCT   
      4314490.9    439104.0    439104.0    439104.0    439104.0   644     4    0.176    4.253
```

 -gcutil：显示垃圾收集信息 

```css
[root@- ~]# jstat -gcutil -t 17338
Timestamp         S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   
      4314594.9   0.89   0.00  52.34   4.19  98.48  95.78    644    4.077     4    0.176    4.253
```

 -printcompilation：输出HotSpot编译方法的统计 

```csharp
[root@- ~]# jstat -printcompilation -t 17338
Timestamp       Compiled  Size  Type Method
      4314622.9    12827    173    1 org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders canRebalance
```

**其他选项：**

- -t：在输出信息前加入一个时间戳，显示程序的运行时间
- -h：在周期性数据输出时，输出多少行数据后，跟着输出一个表头信息
- interval：指定输出统计数据的周期（毫秒）
- count：指定一共输出多少次数据



##### 2.3 jinfo命令

jinfo可以查看正在运行的Java程序的JVM参数，并且支持运行时修改个别参数。

```css
jinfo [option] <pid>
```

**option可选项：**

-  **-flag **         to print the value of the named VM flag，打印指定JVM的参数值
-  **-flag [+|-]**    to enable or disable the named VM flag，设置指定JVM参数的boolean值
-  **-flag =** to set the named VM flag to the given value，设置指定JVM参数值
-  **-flags**               to print VM flags，打印JVM的参数值
-  **-sysprops**            to print Java system properties，打印Java系统的属性信息
-  ****          to print both of the above，打印flags和syspros

##### 2.4 jmap命令

jmap命令能生成Java应用程序的堆快照和对象的统计信息。

```cpp
jmap -histo 17338 > jmap.log
```

```bash
num     #instances         #bytes  class name
----------------------------------------------
   1:        119627       16888576  [C
   2:         74845        8336640  [B
   3:         14991        3763272  [I
   4:         66990        3215520  java.lang.management.MemoryUsage
   5:         32973        2374056  java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask
   6:         42965        2055352  [Ljava.lang.Object;
   7:         81756        1962144  java.lang.String
   8:          9035         994824  java.lang.Class
   9:          6709         858752  sun.nio.fs.UnixFileAttributes
  10:         24718         790976  sun.nio.fs.UnixPath
  ... ...
3729:             1             16  sun.util.resources.LocaleData$LocaleDataResourceBundleControl
Total       1077805       61629024
```

**上述命令输出了内存中实例的数量和大小。**

**生成堆快照信息：**

```swift
jmap -dump:format=b,file=heap.hprof 17338
```

##### 2.5 jhat命令

jhat命令可以分析Java程序的堆快照。

```csharp
[root@- ~]# jhat heap.hprof 
Reading from heap.hprof...
Dump file created Wed Mar 15 15:42:02 CST 2017
Snapshot read, resolving...
Resolving 1183100 objects...
Chasing references, expect 236 dots............................................................................................................................................................................................................................................
Eliminating duplicate references............................................................................................................................................................................................................................................
Snapshot resolved.
Started HTTP server on port 7000
Server is ready.
```

可以通过浏览器访问7000端口查看堆快照信息。

##### 2.6 jstack命令

用于输出Java应用程序的线程栈信息。

```java
public class DeadLockMain {
    private static String A = "A";
    private static String B = "B";

    public void deadLock() {
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (A) {
                    try {
                        TimeUnit.SECONDS.sleep(2);
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                    synchronized (B) {
                        System.out.println("thread1");
                    }
                }
            }
        });
        Thread t2 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (B) {
                    synchronized (A) {
                        System.out.println("thead2");
                    }
                }
            }
        });
        t1.start();
        t2.start();
    }

    public static void main(String[] args) {
        new DeadLockMain().deadLock();
    }
}
```

 上述代码是一个简单的会发生死锁的例子，两个线程分别持有A和B，并分别请求B和A，导致死锁产生。
 使用`jstack`打印上述进程的线程栈信息，部分输出如下： 

```csharp
"Thread-1" #9 prio=5 os_prio=0 tid=0x00007f0ff410b000 nid=0x56d9 waiting for monitor entry [0x00007f0fe4bfa000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at command.DeadLockMain$2.run(DeadLockMain.java:33)
    - waiting to lock <0x00000000e2a77cc0> (a java.lang.String)
    - locked <0x00000000e2a77cf0> (a java.lang.String)
    at java.lang.Thread.run(Thread.java:745)

"Thread-0" #8 prio=5 os_prio=0 tid=0x00007f0ff40fb000 nid=0x56d8 waiting for monitor entry [0x00007f0fe4cfb000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at command.DeadLockMain$1.run(DeadLockMain.java:23)
    - waiting to lock <0x00000000e2a77cf0> (a java.lang.String)
    - locked <0x00000000e2a77cc0> (a java.lang.String)
    at java.lang.Thread.run(Thread.java:745)
       Found one Java-level deadlock:
=============================
"Thread-1":
  waiting to lock monitor 0x00007f0fd8004e28 (object 0x00000000e2a77cc0, a java.lang.String),
  which is held by "Thread-0"
"Thread-0":
  waiting to lock monitor 0x00007f0fd80062c8 (object 0x00000000e2a77cf0, a java.lang.String),
  which is held by "Thread-1"

Java stack information for the threads listed above:
===================================================
"Thread-1":
    at command.DeadLockMain$2.run(DeadLockMain.java:33)
    - waiting to lock <0x00000000e2a77cc0> (a java.lang.String)
    - locked <0x00000000e2a77cf0> (a java.lang.String)
    at java.lang.Thread.run(Thread.java:745)
"Thread-0":
    at command.DeadLockMain$1.run(DeadLockMain.java:23)
    - waiting to lock <0x00000000e2a77cf0> (a java.lang.String)
    - locked <0x00000000e2a77cc0> (a java.lang.String)
    at java.lang.Thread.run(Thread.java:745)

Found 1 deadlock.
```



































































































### 负载均衡

- Nginx软负载  高性能的 HTTP和反向代理服务器,性能好、稳定、功能丰富(异步、故障检测转移)、资源消耗低(1万并发)、受自身性能限制
    - master process负责读取配置、绑定接口
    - worker process负责网络连接、硬盘读写、网络通信
- F5硬件负载  算法多样、故障自动转移、会话保持、定向定制、价格昂贵

### 杂项

- 正向代理指用户明确知道去哪,但需要走代理(翻墙); 反向代理指用户也不知道去哪(负载均衡)
- 死锁条件: 资源互斥，循环等待，请求和保持，不可剥夺
- 线程池的等待队列的长度(queSize<=ClientTimeOut *TPS), 当线程池核心数均被占用,则新入任务会进入等待队列, 等待队列满才会触发新线程的创建;当达到最大线程数,则会触发拒绝策略
- CAS自旋volatile变量
- 泛型约束可以使用& 如: T extends Number & Comparable<? super T>
- CAS参数(对象,偏移量,期望值,更新值)

##     框架

### AQS[AbstractQueuedSynchronizer]

顾名思义,同步队列,定义了一个FIFO等待队列和一个volatile的state状态量,支持独占式和共享式资源两种模式. 自定义同步器只需要实现state的获取和释放,而队列的维护已由框架封装. tryAcquire()，tryRelease()为主要方法.流程如下

- 尝试获取锁tryAcquire(),获取成功则直接返回
- 111111111addWaiter()增加Node,置为队尾, 并标记模式[独占式/共享式]
- acquireQueued() 入队,等待被唤醒[head结点,就是当前获取到资源的那个结点或null]
- 补中断[线程在等待过程中被中断过,它是不响应的.只是获取资源后才再进行自我中断selfInterrupt(),将中断补上]

<img src="./jNote/AQS.png"/>

应用

- CountDownLatch 初始化state=N,当state CAS为0时,unpark主线程
- CyclicBarrier 初始化state=N,当state CAS为0时,重置为N
- Semaphore 初始化为N,不支持重入,获取-1,释放+1
- ReentrantLock、Share 初始化为0,支持重入,获取+1,释放-1
- Condition



### springMVC

#### 架构

#### CROS

### springboot

#### Bean生命周期

<img src='./jNote/beanLifecycle.png'/>

#### 自动装配

### springcloud

### zookeeper

#### 选举

<img src='./jNote/zkRoles.jpg'/>

- ZXID是一个64位的数字, 低32位是一个简单的单调递增的计数器,高32位则代表Leader周期epoch的编号;每当Leader选出, 就会收集各个follower epoch值,+1后作为新的epoch,并将低32位重置0
- 当Leader不可达,ZK停止服务,并进入恢复模式(选举阶段)
- 发现阶段, Follower广播竞选,类Paxos过程,得到半数以上的节点当选准Leader(准Leader ZXID最新)
  - 投票含基本信息ZXID、SID(server id)、回合、LOOKING信息等,ZXID越大越优先,SID次优先
- 同步阶段, 准Leader同步epoch、同步Proposal集合
  - 准leader先收集各follower的epoch,并选取最大的,+1后同步
  - 准leader根据反馈的ZXID选取适当的初始Proposal集合进行数据同步
- 广播阶段, 对外提供事务服务
- ZK提供了sync()方法,用于同步数据
- ZK通过Quorums机制防止脑裂

```
准leader选举过程示例:
假设当前集群中有5台机器组成。sid分别为1，2，3，4，5。zxid分别为9，9，9，8，8，并且此时sid为2的机器是leader。某一时刻，1和2的服务器挂掉了，集群开始进行选主。
在第一次投票中，由于无法检测到集群中其他机器的状态信息，因此每台机器都将自己作为被推举的对象来进行投票。于是sid为3，4，5的机器，投票情况分别为（3，9），（4，8），（5，8）
每台机器把投票发出后，同时也会接收到来自另外两台机器的投票。
对于server3来说，接收到（4，8），（5，8）的投票，对比后由于自己的zxid要大于收到的另外两个投票，因此不需要做任何变更。
对于server4来说，接收到（3，9），（5，8）的投票，对比后由于（3，9）这个投票的zxid大于自己，因此需要变更投票为（3，9），然后继续将这个投票发送给另外两台机器。
对于server5来说，接收到（3，9），（4，8）的投票，对比后由于（3，9）这个投票的zxid大于自己，因此需要变更投票为（3，9），然后继续将这个投票发送给另外两台机器。
经过第二轮投票后，集群中的每台机器都会再次受到其他机器的投票，然后开始统计投票。判断是否有过半的机器收到相同的投票信息，如果有，那么该投票的sid会成为新的leader。
```



#### 分布式锁

```java
@Configuration
class ZLockConfig{
    @Bean
    @ConditionalOnMissingBean
    public ZLock zLock(){
        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);
        CuratorFramework client = CuratorFrameworkFactory.newClient("127.0.0.1:2181",5000,3000,retryPolicy);
        client.start();
        return new ZLock(client);
    }
}
class ZLock{
    private CuratorFramework client;
    public ZLock(CuratorFramework client) {
        this.client=client;
    }
    public <T> T executor(String lockId, Long timeout, @NotNull Callback callBack)throws InterruptedException{
        boolean getLock=false;
        ZkReentrantLock zkReentrantLock = null;
        try{
            zkReentrantLock=new ZkReentrantLock(client,lockId);
            if(zkReentrantLock.tryLock(timeout,TimeUnit.MILLISECONDS)){
                getLock=true;
                return (T)callBack.onGetLock();
            }else {
                return (T)callBack.onTimeout();
            }
        }catch (Exception e){
            log.error(e);
        }finally {
            if(getLock){
                zkReentrantLock.unLock();
            }
        }
        return null;
    }
}
@Slf4j
class ZkReentrantLock{
    private static final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(10);
    public static final String ROOT_PATH = "/ROOT_LOCK/";
    private long delayTimeForClean = 1000;
    private InterProcessMutex interProcessMutex = null;
    private String path;
    private CuratorFramework client;
    private final long DEFAULT_TIMEOUT=5000L;
    public ZkReentrantLock(CuratorFramework client, String lockId) {
        this.client=client;
        this.path=ROOT_PATH+lockId;
        this.interProcessMutex=new InterProcessMutex(client,this.path);
    }

    public boolean tryLock(Long timeout, TimeUnit unit)throws InterruptedException {
        try {
            return interProcessMutex.acquire(timeout==null?DEFAULT_TIMEOUT:timeout, unit==null?TimeUnit.MILLISECONDS:unit);
        } catch (InterruptedException e) {
            throw e;
        } catch (Exception e) {
            log.error(e.getMessage(),e);
            throw new RuntimeException(e.getMessage(),e);
        }
    }

    public void unLock() {
        try {
            interProcessMutex.release();
        } catch (Throwable e) {
            log.error(e.getMessage(), e);
        } 
    }
}

interface Callback<T> {
    public T onGetLock() throws InterruptedException;
    public T onTimeout() throws InterruptedException;
}
```

zk curator分布式锁原理(重入锁)
tryLock: 判定本地ConcurrentMap中是否包含线程id, 有则重入(不请求远端), 否则尝试请求远端建立lockId节点(节点类型为EPHEMERAL_SEQUENTIAL, lockId+序列号); 获取锁(只有在watch时刚好要watch的节点被删除,或被唤醒时, 触发循环)时, 查看当前节点是不是最小节点, 如果是则获取到锁返回, 如果不是, 则对上一个节点添加watch,线程wait等待被唤醒
unLock: 从本地ConcurrentMap取出本地量,尝试decrementAndGet, 并在减为0时删除远端节点

- zk不适合大规模集群(维护数据一致性), qps、tps大概在5w左右, 如超过请采用其他分布式架构
- zk写在leader节点,读在任意节点
- zk不是为了高可用设计的,可用来保证强一致性
- zk保证的CAP中的A可用性、P分区容错性和C中的写入强一致,但不保证多客户端C的读取一致性
- zk节点分类三类Leader、Follower、Observer, 其中Follower参与选主、写多数确认,而Observer只提供读服务

### mybatis

#### mybatis缓存

mybatis缓存有两级,执行写操作,缓存会被清空
第一级为sqlSession级(sqlSession是事务级别的,不同事务sqlSession不同)
第二级为mapper namespace级别的,每个namespace里有一个HashMap存储数据(默认关闭)
分布式情况下,二级缓存不通用,需要自定义三级缓存, 如使用分布式缓存框架ehcache等

#### PageHelper原理

pagehelper的startPage会向ThreadLocal保存一个Page对象,包含设定的分页参数(pageSize==0时,不分页)
Page对象有个doSelectPage函数接口,用以执行查询语句(mapper查询)
pagehelper有个PageInterceptor拦截器(实现自mybatis,在pagehelper-spring-boot-autoconfigure中配置),用于拦截mapper的查询结果,并将其封装到Page对象中
PageInterceptor是核心,它拦截了Executor的query方法,pagehelper在拼装分页参数时,原始SQL不能有Order By,LIMIT限定,有则报错

### dubbo

### MQ

- 使用场景  <b>削峰、发布订阅、异步处理、应用解耦、分布式事务(最终一致性)</b>
  - 解耦/发布订阅 不需要关心下游如何处理(保证不丢消息即可)
  - 削峰 防止雪崩
- 缺陷  <strong>系统可用性降低、系统复杂度提高、一致性问题</strong>
- 设计 <strong>主要从可伸缩、消息不丢失、高可用等方面展开</strong>

#### rocketMQ

<img src='./jNote/rocketMQ.jpg'/>

- 基础概念
    - nameServer 注册中心 nameServer无信息同步
    - producer/consumer 生产者/消费者 与注册中心某一节点保持长连接, 与broker保持长连接
    - broker集群(master/slave) broker与nameServer所有节点保持长连接, 注册Topic
        - 同步双写 
        - 异步复制
    - topic 标志消息类型(分布于多个broker)
    - tag  消息子类型 利用topic订阅消息,利用tag过滤消息
    - queue 一个topic对应多个queue
- 消费模式 push/pull
    - 普通消费  广播消费/集群消费
      - 广播消费的offset持久化在client本地,拉取消息时传入offset
      - 集群消费的offset保存在broker,并定时序列化到磁盘
    - 顺序消费  即将一组有先后循序的消息投递到某一broker的固定queue,并指定消费方顺序消费
    - 回溯消费 调整offset,或是指定回溯时间
    - 消费策略 At last one至少一次(收到ack为准)、Exactly Only Once仅有一次(rocketMQ不保证)
    - 优先级/延时 rocketMQ不支持严格的优先级,可使用不同topic分级处理  只支持几个等级的延时

- 消息过滤/防重
  - broker端过滤 减少网络传输、实现复杂
  - consumer端过滤/防重 实现简单、消耗带宽

  <img src='./jNote/rocketMQReadWrite.jpg'/>

- 持久化(文件形式)rocketMQ充分利用Linux的内存cache提高性能
  - 消息顺序写 顺序写commitLog,并将消息dispatch到各个queue(不存储消息实体,仅含offset,size等)
  - 消息随机读 先顺序读queue,根据地址到commitLog随机读消息实体
  - indexFile 提供消息按时间段,Key等查询消息的索引文件
  - commitLog默认大小1G,主要是由于MappedByteBuffer(直接内存)映射数据量大小有限制
  - rocketMQ利用内存预分配,文件预热,mlock系统调用优化读写性能
    - 内存预分配 预先分配下一个、下下一个CommitLog的文件映射
    - 文件预热  分配内存后写入随机值保证内存占用、map映射后为防止缺页调用madvise
    - mlock系统调用  锁定内存,防止其被交换到swap空间
  - broker正常关闭、broker异常Crush、OS Crush、机器掉电恢复 broker节点可正常工作
  - 机器损坏、磁盘损坏 broker单点故障,人工干预
  - 刷盘方式 同步刷盘(commitlog) 不会丢失消息、异步刷盘可能丢失少量数据
  - 复制方式 同步双写保证单点故障后slave正常工作、异步复制slave可能丢失少量数据
- 拒绝策略 rocketMQ不存在buffer概念,所以不拒绝消息
  - rocketMQ会72小时删除数据,积压太多,需要接入报警
  - rocketMQ无拒绝策略,会导致磁盘打满,需要监控磁盘使用情况

- 事务(broker是一个天然的协调点)<img src='./jNote/mqTransaction.png'/>
- 杂项
  - broker宕机后,comsumer仍可从slave读取数据消费,消息会写入到其他broker
  - 顺序消费场景,broker宕机可能会引起部分数据不一致(顺序消费消息会发到同一个queue)
  - 不建议开启自动创建topic,可能会导致仅在单broker上有queue
    - 发消息后,无法获取topic路由,会在某一个broker自动创建topic,并将其注册到nameserver
    - 之后的消息能在nameserver获取路由,导致消息全部发送到单点broker
  - 消息幂等都消费端结合具体业务场景实现(如:数据库log+消息唯一ID)
  - 一般采用confirm机制保证数据写入(不因网络问题导致消息丢失)
  - MQ消息积压,可通过临时增加consumer节点解决
  - MQ消息丢失,人工介入补发消息


#### kafka

##### 基础概念

##### 消费防重/丢失

- kafka 自动提交offset会导致消息丢失(未来得及消费,宕机)
- kafka 手动提交offset会导致消息重复消费

### xxlJob

```java
@Slf4j
//@Component
@JobHandler(value = "taskName")
public class Task extends IJobHandler {
    //@Resource 注入Service
    @Override
    public ReturnT<String> execute(String param) {
        long start = System.currentTimeMillis();
        try{
        	XxlJobLogger.log("task 开始时间:{0}",start);
            //定时操作逻辑代码
            XxlJobLogger.log("task 成功,耗时:{}",System.currentTimeMillis()-start);
            return ReturnT.SUCCESS;
        } catch (Exception e) {
            XxlJobLogger.log("task 失败");
            XxlJobLogger.log(e);
            return ReturnT.FAIL;
        }
    }
}
```

<img src="./jNote/xxljob.jpg"/>



### Ehcache



### Redisson

Redisson分布式锁是Redis提供给的官方分布式锁框架. RLock继承了标准的Lock, 拥有标准锁的一切特性.提供重入超时等策略. 提供了单锁、联合锁、RedLock、读写锁、信号量等
加锁阶段:(KEYS[1] key, ARGV[1] timeout, ARGV[2] threadId)
tryLock: 执行lua脚本尝试获取锁,获得返回true;失败则订阅Redis事件,若超时时间内订阅返回则循环tryLock获取锁,若不返回则直接返回false;  加锁阶段设置了线程ID,仅允许对应的线程解锁, 如果线程挂掉,则只能依赖机制. 

```lua
if (redis.call('exists', KEYS[1]) == 0) then 
redis.call('hset', KEYS[1], ARGV[2], 1); 
redis.call('pexpire', KEYS[1], ARGV[1]); 
return nil; end; 
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then 
redis.call('hincrby', KEYS[1], ARGV[2], 1); 
redis.call('pexpire', KEYS[1], ARGV[1]); 
return nil; end; 
return redis.call('pttl', KEYS[1]);
//判断lock键存在?不存在直接调用hset存储当前线程信息并且设置过期时间,返回nil,告诉客户端直接获取到锁
//判断lock键存在?存在则将重入次数加1,并重新设置过期时间,返回nil,告诉客户端直接获取到锁
//被其它线程已经锁定,返回锁有效期的剩余时间,告诉客户端需要等待
```

lock: 不会设置尝试获取超时时间. 加锁阶段(没超时机制时)设置了看门狗(会检测调用方是否存活), 会设置一个默认超时间, 并在线程锁超时前延长超时时间(存活情况),挂掉了则依赖超时

解锁阶段:

unlock: 解锁

```lua
if (redis.call('exists', KEYS[1]) == 0) then
 redis.call('publish', KEYS[2], ARGV[1]);
 return 1; end;
if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then 
return nil;end; 
local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); 
if (counter > 0) then redis.call('pexpire', KEYS[1], ARGV[2]); return 0; 
else redis.call('del', KEYS[1]); redis.call('publish', KEYS[2], ARGV[1]); return 1; end; 
return nil;
//如果lock键不存在，发消息说锁已经可用
//如果锁不是被当前线程锁定，则返回nil
//由于支持可重入，在解锁时将重入次数需要减1
//如果计算后的重入次数>0，则重新设置过期时间
//如果计算后的重入次数<=0，则发消息说锁已经可用
```



### 杂项

#### filter与Interceptor区别

filter是Servlet提供的过滤链(基于注册调用)
interceptor是由springMVC提供的切面拦截器(基于反射/AOP)

#### 加密解密

- 公钥加密 私钥解密[加解密,只希望接收方解密(私钥)]
- 私钥签名 公钥验签[验签, 由公钥方验证消息来源]

#### Spring 打war包

继承SpringBootServletInitializer覆盖config方法,并确保web.xml存在

```java
protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {
  return application.sources(Application.class);
}
```

#### 获取SpringBean

实现ApplicationContextAware的setApplicationContext

#### @Autowired VS @Resource

@Autowired和@Resource都用作注入资源:@Autowired默认使用ByType匹配,可配合@Qualifier实现按照名称匹配;@Resource有ByName和ByType两个属性,显式的指定任意一个或两个属性都会退化成强制匹配,缺省时按照ByName匹配,匹配失败后退化为ByType匹配

#### 点滴

- 
- 微服务使用zipkin分析调用链,防止调用链过长
- dubbo安全机制,使用token令牌防止跳过注册中心服务直连,允许服务方设置白名单
- dubbo防止应用启动失败,可将consumer的检查设置为false
- dubbo的provider的delay属性设置为-1,可防止dubbo容器未初始化完毕对外提供服务
- RedLock在集群模式下不安全

##     容器

### tomcat

#### 架构

<img src='./jNote/tomcat.jpg'/>

- Catalina tomcat顶层容器,通过创建Catalina实例对象启动/关闭tomcat
- Server 管理tomcat的所有组件,包含多个Service
- Service 包含Connector和Container的集合; Service用适当的Connectoe接收用户请求再发给相应的Container处理
- Connector 主要负责socket接收/处理(HTTP,AJP),Request/Response创建封装,交予Container
- Container 接收Connector请求,利用Pipeline往子容器传递(责任链模式), 亦包含Loader(类加载器)、Manager(Session池管理)、Realm(权限管理)等模块
- Engineer 根据getHost() 定位Host
- Host 指向虚拟主机
- Context Web应用上下文
- Wrapper 对应一个具体的Servlet

tomcat面向组件架构, 基于JMX注册各个组件, 同时基于事件监听(观察者模式)进行行为扩展

#### 加载器模型

<img src='./jNote/tomcatClassLoader.jpg'/>

原始的双亲加载模型不能满足tomcat需求, tomcat实现了类加载器结构如上,主要解决如下问题:

- 允许不同版本第三方类库同时存在, 且保证同一版本有且仅有一份
- 实现tomcat自身依赖的类库与web应用的依赖库的隔离
- 支持JSP等Servlet的热替换

其中(Webapp下的jar并不在classpath下,所以不会被系统类加载器提前加载)

- CommonClassLoader负责加载Tomcat容器本身/Webapps共有的访问类
- CatalinaClassLoader负责加载Tomcat私有类, 对Webapps不可见
- SharedClassLoader负责加载Webapps共有的类, 对Tomcat不可见
- WebappClassLoader负责加载各个Webapp私有的类加载器(违背双亲加载规则,自己玩自己的)
- JasperLoader负责处理各个JSP(当JSP被修改后,之前的Class会被丢弃,实现热加载)

### jetty

### docker



##     工具

### Netty

参考 netty in action

#### Netty采用NIO而不是AIO

- Netty更看重其在Unix系系统上的使用; AIO底层实现仍然是EPOLL,实现并无优势,且被JDK封装,不易深层优化
- Netty整体架构模型是reactor,而AIO使用proactor模型,兼容混乱
- AIO需要预先分配内存,对于连接多流量小的情况,浪费内存

### gson

```java
@Slf4j
public class GsonUtil {
    private GsonUtil() {}
    private static final Gson GSON;
    protected static final String[] DATE_PATTERNS = new String[]{"yyyy-MM-dd", "yyyyMMdd", "yyyy/MM/dd", "yyyy年MM月dd日"};
    protected static final String[] TIME_PATTERNS = new String[]{"HH:mm:ss", "HHmmss", "HH时mm分ss秒"};
    protected static final String[] DATE_TIME_PATTERNS = new String[]{"yyyy-MM-dd HH:mm:ss", "yyyyMMddHHmmss", "yyyy年MM月dd日HH时mm分ss秒"};
    private static final ZoneId SYSTEM_DEFAULT_ZONE_ID =ZoneId.systemDefault();
    static {//初始化
        GSON = new GsonBuilder()
                .setDateFormat(DATE_TIME_PATTERNS[0])
                .registerTypeAdapter(LocalDate.class, (JsonSerializer<LocalDate>) (localDate, type, context) -> new JsonPrimitive(localDate.format(DateTimeFormatter.ISO_LOCAL_DATE)))
                .registerTypeAdapter(LocalTime.class, (JsonSerializer<LocalTime>) (localTime, type, context) -> new JsonPrimitive(localTime.format(DateTimeFormatter.ISO_LOCAL_TIME)))
                .registerTypeAdapter(LocalDateTime.class, (JsonSerializer<LocalDateTime>) (localDateTime, type, context) -> new JsonPrimitive(localDateTime.format(DateTimeFormatter.ofPattern(DATE_TIME_PATTERNS[0]))))
                .registerTypeAdapter(LocalDate.class, (JsonDeserializer<LocalDate>) (element, type, context) -> {
                    String date = element.getAsJsonPrimitive().getAsString();
                    for (String datePattern : DATE_PATTERNS) {
                        try {
                            return LocalDate.parse(date, DateTimeFormatter.ofPattern(datePattern));
                        } catch (DateTimeParseException ignored) {
                            log.debug("DateTimeParseException of date pattern ,{}",ignored);
                        }
                    }
                    try {
                        return ISO8601Utils.parse(date, new ParsePosition(0)).toInstant().atZone(SYSTEM_DEFAULT_ZONE_ID).toLocalDate();
                    } catch (ParseException e) {
                        log.debug("ParseException of date,{}",e);
                        throw new JsonSyntaxException(date, e);
                    }
                })
                .registerTypeAdapter(LocalTime.class, (JsonDeserializer<LocalTime>) (element, type, context) -> {
                    String time = element.getAsJsonPrimitive().getAsString();
                    for (String timePattern : TIME_PATTERNS) {
                        try {
                            return LocalTime.parse(time,DateTimeFormatter.ofPattern(timePattern));
                        } catch (DateTimeParseException ignored) {
                            log.debug("DateTimeParseException  of time pattern,{}",ignored);
                        }
                    }
                    throw new JsonSyntaxException(time);
                })
                .registerTypeAdapter(LocalDateTime.class, (JsonDeserializer<LocalDateTime>) (element, type, context) -> {
                    String dateTime = element.getAsJsonPrimitive().getAsString();
                    for (String dateTimePattern : DATE_TIME_PATTERNS) {
                        try {
                            return LocalDateTime.parse(dateTime, DateTimeFormatter.ofPattern(dateTimePattern));
                        } catch (DateTimeParseException ignored) {
                            log.debug("DateTimeParseException of datetime pattern,{}",ignored);
                        }
                    }
                    try {
                        return ISO8601Utils.parse(dateTime, new ParsePosition(0)).toInstant().atZone(SYSTEM_DEFAULT_ZONE_ID).toLocalDateTime();
                    } catch (ParseException e) {
                        log.debug("ParseException of datetime,{}",e);
                        throw new JsonSyntaxException(dateTime, e);
                    }
                })
                .addSerializationExclusionStrategy(new ExcludeStrategy())
                .create();
    }
    public static <T> T fromJson(String jsonStr, Class<T> clazz) {
        try {
            return GSON.fromJson(jsonStr, clazz);
        } catch (JsonSyntaxException e) {
            log.error("GSON.fromJson error", e);
        }
        throw new IllegalArgumentException();
    }
    public static <T> T fromJson(String jsonStr, Type type) {
        return GSON.fromJson(jsonStr, type);
    }
    public static String toJson(Object obj) {
        return GSON.toJson(obj);
    }
    public static String toJson(Object obj, Type type) {
        return GSON.toJson(obj, type);
    }
    @Documented
    @Retention(RetentionPolicy.RUNTIME)
    @Target({ElementType.FIELD,ElementType.TYPE})
    public @interface FieldExclude {}
    private static class ExcludeStrategy implements ExclusionStrategy {
        public boolean shouldSkipClass(Class<?> clazz) {
            return clazz.getAnnotation(FieldExclude.class) != null;
        }
        public boolean shouldSkipField(FieldAttributes f) {
            return f.getAnnotation(FieldExclude.class) != null;
        }
    }
}
```

### redission

参考 框架 Resission

### maven

参考印象笔记

### druid

- 强大的监控特性(Filter chain) spring.datasource.druid.filters=stat,wall,log4j
- 异常监控ExceptionSorter,连接产生不可恢复异常时将其剔除
- 数据库连接LRU

##     配置

### Redisson

```java
redisson.node-address[0] = redis:10.8.8.23:8501
redisson.node-address[1] = redis:10.8.8.23:8502
redisson.node-address[2] = redis:10.8.8.23:8503
redisson.node-address[3] = redis:10.8.8.23:8504
redisson.node-address[4] = redis:10.8.8.23:8505
redisson.node-address[5] = redis:10.8.8.23:8506
redisson.password = password
redisson.scan-interval=1000
@ConfigurationProperties(prefix = "redisson")
@Data
public class RedissonProperties {
    private String[] nodeAddress;//节点
    private String password;//密码
    private Integer scanInterval;//扫描间隔
}
@Bean("redisson")
public RedissonClient redisson() {
    Config config = new Config();
    config.useClusterServers()
        .addNodeAddress(properties.getNodeAddress())
        .setPassword(properties.getPassword())
        .setScanInterval(properties.getScanInterval());
    return Redisson.create(config);
}
```

### xxljob

```
xxl.job.enable=true
xxl.job.app-name=${spring.application.name}
xxl.job.log-path=${logging.path}
xxl.job.admin-addresses = http://10.8.8.24:8130/
xxl.job.ip = 
xxl.job.port = 9121
xxl.job.access-token = 
xxl.job.log-retention-days = -1
@Configuration
@EnableConfigurationProperties(JobConfig.JobProperties.class)
public class JobConfig {
    @Resource
    private JobProperties properties;
    @Bean(name = "xxlJob", initMethod = "start", destroyMethod = "destroy")
    @ConditionalOnMissingBean
    @ConditionalOnProperty(prefix = "xxl.job", name = "enable", havingValue = "true")
    public XxlJobExecutor xxlJob() {
        XxlJobExecutor xxlJobExecutor = new XxlJobExecutor();
        xxlJobExecutor.setAdminAddresses(properties.getAdminAddresses());
        xxlJobExecutor.setAppName(properties.getAppName());
        xxlJobExecutor.setIp(properties.getIp());
        xxlJobExecutor.setPort(properties.getPort());
        xxlJobExecutor.setAccessToken(properties.getAccessToken());
        xxlJobExecutor.setLogPath(properties.getLogPath());
        xxlJobExecutor.setLogRetentionDays(properties.getLogRetentionDays());
        return xxlJobExecutor;
    }
    @Data @ConfigurationProperties(prefix = "xxl.job")
    public class JobProperties {
        private String adminAddresses;//调度器地址
        private String appName;//应用名称
        private String ip;//ip
        private int port;//端口
        private String accessToken;//token
        private String logPath;//日志路径
        private int logRetentionDays;//日志保留天数
    }
}
```

### Dubbo

```java
dubbo.scan.basePackages = com.virgo.finance.cpc.auth.web.impl
dubbo.application.name = cpc-auth
dubbo.application.logger = slf4j
dubbo.registry.file = /data/LOGS/cache/cpc-auth.cache
dubbo.provider.version = 1.0.0
dubbo.provider.timeout = 10000
dubbo.consumer.check = false
dubbo.consumer.version = 1.0.0
dubbo.consumer.retries = 0
dubbo.consumer.timeout = 10000
dubbo.application.qos.enable = true
dubbo.application.qos.port = 33337
dubbo.application.qos.accept.foreign.ip = false
dubbo.protocol.port = 20967
dubbo.registry.address = zookeeper://10.20.153.10:2181?backup=10.20.153.11:2181
```

## 场景

### 缓存一致性

方案:使用分布式锁 类似RLock实现; 读检查锁key存在则直接(删除缓存)穿透缓存,不存在则读缓存(缓存不存在则到数据库并缓存之);写操作, 先设置锁(利用watchDog和超时实现锁的一定会释放)更新数据库,删除缓存并解锁

缓存不应作为强一致性场景的工具, 要求强一致性可以使用数组库主从读写分离

### 熔断机制


## 项目

### 富民网贷核心

### 小拇指账户系统

### NettyRPC

##     杂项

### Redis和Memcached比较

redis数据结构多样,支持订阅,单核,提供持久化; memCached仅支持key/value, 多核, 无持久化
锁, 会话缓存, 全页缓存,排行榜, 发布订阅可以使用Redis
小视频/图片可以使用Memcached(小于1M)

### 一致性hash 

## [一致性哈希算法原理分析及实现](https://www.cnblogs.com/markcd/p/8476237.html)

一致性哈希算法常用于**负载均衡**中要求资源被均匀的分布到所有节点上，并且对资源的请求能快速路由到对应的节点上。具体的举两个场景的例子：

​    1、**MemCache集群**，要求**存储各种数据**均匀的存到集群中的各个节点上，访问这些数据时能快速的路由到集群中对应存放该数据的节点上；并且要求增删节点对整个集群的影响很小，不至于有大的动荡造成整体负载的不稳定；

​    2、RPC过程中服务提供者做N个节点的集群部署，为了能在服务上维护一些业务状态，希望**同一种请求每次都落到同一台服务上。**



​    一致性哈希算法的思路为：先构造出一个长度为2^32整数环，根据N0-3的节点名称的hash值（分布为[0,232-1]）放到这个环上。现在要存放资源，根据资源的Key的Hash值（也是分布为[0,232-1]）值Haaa，在环上顺时针的找到离Haaa最近（第一个大于或等于Haaa）的一个节点，就建立了资源和节点的映射关系。

- hash机器, 数据转移
- 
- 一致性hash在节点较少时容易造成分布不均,可采用虚拟节点解决(数据hash到虚拟节点,再映射到真实节点)

### 惊群效应

避免znode改变时触发所有watches事件

### 脑裂

脑裂问题会影响数据读取,但不影响数据写入(一半以上才会认为写入成功)

 - 增加通信渠道 即不要依赖单一链路通讯,避免假死现象
 - 启用磁盘锁 即对资源加锁, 无论哪个leader占用, 谁抢到就是谁的
 - 设置仲裁机制,增加参考IP 当心跳断开则ping参考ip, 如果ping不通, 则重启自己释放资源
 - 做好监控, 通知, 及时人工介入

### 分布式一致性算法

#### Raft(开源实现etcd)

Raft包含两个过程(主节点选取,数据同步), 三种角色(Leader、Follower、Candidate)，选举流程

- 最初,所有节点都为Follower,各Follower持有时钟(心跳重置),当时钟超时(时钟超时时间不一致),角色转换为Candidate
- Candidate会先向自己投票, 并向所有的节点发起投票请求(每个节点只能对外投送一票,先到先得)
- 当Candidate获取票数超过集群一半,自动晋升为Leader,并向其它节点发送follow信号,并重置他们的时钟
- Leader定时发送心跳重置Follower时钟,防止被篡位

数据流程(类似XA两步提交), Raft算法可防止脑裂, 网络恢复后<b>旧有Leader降级为Follower</b>

- 用户数据提交至Leader, Leader分发写操作(不断重试),未提交,并等待确认
- 当Leader收到半数ACK, 表明数据复制成功, Leader提交数据,告知客户端提交成功, Leader分发commit操作

异常处理(Leader异常情况)

- 数据未到达Leader, 不影响一致性
- 数据到达Leader,未复制Follower, 用户无法得到ACK应答, Client重试, 不影响一致性
- 部分Follower, 未ACK到Leader, 重选举Leader后可完成提交(选举拥有最新数据的节点), 需实现Client提交幂等
- 多数Follower, Leader已提交，Follower未提交, 同上

#### ZAB

- ZAB选举基于ZXID选择(ZXID是一个递增版本ID,崩溃恢复阶段选取ZXID最大的节点做为新任Leader)
  - ZK每次写都是事物,每次写操作都会触发ZXID递增,Leader会根据ZXID版本提交或回滚事务
- ZAB数据流程与Raft类似(半数ACK),但采用了异步方式(队列)避免同步阻塞
- ZAB保证的是内部数据一致性,而不是客户端读到的数据的一致性(即可能读到旧数据)

#### Basic Paxos(实现chubby)

<img src="./jNote/paxos.jpg"/>

#### Muti Paxos

Basic Paxos情况比较复杂,且容易陷入重试循环,一般采用Muti Paxos,一次性决定多个值

#### 比较

- ZAB

### 高可用系统设计

- 减少单点、集群部署,减少所有主链路单点(如机房、服务器,专线调用时考虑同时多根专线)
- 减少依赖、减少远程调用、依赖解耦,减少远程服务依赖、减少DNS依赖(本地host)、利用MQ解耦
- 控制流量、增加限流、削峰、熔断机制,控制异常流量,限制QPS,TPS等
- 限制循环, 避免无限循环,会导致CPU利用百分之百
- 精准监控、弹性扩容,监控节点CPU利用率、load、内存、带宽、调用量、异常量、内存泄漏
- 无状态,服务器集群不要与用户挂钩,会导致无法扩容
- 容量规划、线上压测,定期对容量进行评估、压测,根据需要扩容
- 设置超时、异步调用, 服务调用超时限制,改用异步调用,
- 重试机制, 增加服务重试机制(一定要设置最大调用次数),或是服务并发调用(提高SLA)
- 隔离,机房隔离、应用隔离、模块隔离、线程池隔离
- 热点缓存,缓存热点数据,减少调用,
- 分级缓存、缓存容灾, 如先读本地缓存、再读分布式缓存等
- 系统分级、服务权重, 高优服务不依赖低优服务,保证高优服务可用率,自动识别高可用性服务,智能路由
- 灰度和回滚、功能开关、运行时加载模块,灰度上线,快速回滚,新增功能可控制开关,业务模块动态加载/卸载
- 代码扫描,减少坏味道
- 备份

### Protobuff

- Protobuff序列化将Key:Value Json映射为 Tag|Length|Value 格式数据(长度非必须,若数据类型长度固定,则无须长度)
- Tag、Length、数字型Value 均采用varint格式(压缩Int)
- Tag一般占用一个字节,格式为 Id<<3|Type  Id为编码序号,Type位数据类型
- 对于有符号数字采用zigzag编码后进行压缩

### 分布式锁选择(Redis分布式锁超时 导致多个任务获取锁的解决思路)

如果数据源处不进行修改(比如增加版本号控制),那么没有任何解决方案.
因为不光网络问题, gc的stw阶段, 或者page fault导致的阻塞也是没办法控制的.即使随时随地去判断锁的状态,你仍然没办法去确定判断完后,是否会进入一次gc或者page fault.
redis锁的问题在于, 超时后会自动释放锁. 所以可以考虑使用zk的锁, zk是基于session的锁, 不会有超时时间, 只会在session关闭后释放(但是仍然无法防止长时间gc导致zk检测不到心跳导致的过期).
总结来说就是, 如果只是考虑到效率, 而允许某些情况下同时存在两个进程获取锁, 那么使用redis锁没有任何问题; 如果需要正确性, 那么redis的锁不是一个很好的实现, zk的锁是一个更好的思路, 但是仍然存在问题, 更好的方式是, 数据源处进行修改,增加版本控制或者某些程度上事务(ACID)的支持(这就引入了既然数据源处已经支持了锁,我们还需要分布式锁干什么); 如果对效率不是那么看中, 比如一些异步处理, 那么甚至可以用队列+单线程消费者去处理,天然的免锁.

### 点滴

- classloader.loadClass() 和Class.forName的区别是forName会触发对象初始化
- Runtime.getRuntime().addShutdownHook(shutdownHook)
- jstack打印堆栈信息排查死锁(类初始化时在cinit加锁, 若cinit互相forName对方,会死锁且jstack检测不到)
- 优化GC可以使用jmap,jstat,jps等工具
- tcmalloc可以替换大多数系统、不同编译器环境下的内存分配函数（malloc/free/new/delete)
- 取模方式会导致数据迁移问题(一致性hash)
- ZK保证的是CAP中的A高可用,P分区容错,C的写入一致性,牺牲的是C的读取一致性
- 观察者模式VS发布/订阅 观察者模式观察者和主题互知对方,同步模式;发布/订阅发布方和订阅方互不相知,异步模式
- 队列发送端消息可靠性保障  发送者与消息中间件之间消息落盘(比如加一层数据库)
- 队列接收端消息可靠性保障  幂等、唯一消息ID+日志
- CDN内容分发网络 访问资源就近原则

# 数据库

##     MySQL

### 引擎/索引



 ![img](https://img-blog.csdn.net/20171222103605354) 

innoDB、MyISAM、Memory等

- B+Tree索引  O(logd(N))，d为出度
  - 聚簇索引 主键索引的叶子节点data域记录着完整的数据记录
  - 辅助索引 辅助索引的叶子节点的data域记录着主键的值, 查到后, 回查聚簇索引
  - 覆盖索引 索引域含查询域的所有字段, 不需要回查聚簇索引
  - 自适应哈希索引 某个索引特别频繁时会为其创建hash索引
- 哈希索引 O(1)
  - 无法使用排序和分组
  - 不支持范围查找

### 隔离级别

读未提交 不使用
已提交读(RC) SQLServer和Oracle默认隔离级别(推荐)
    RR级别存在间隙锁, RR引起死锁的概率比RC高得多
    RR级别未命中索引会锁表, RC级别只会锁记录
    MYSQL新版本RC引入了半一致性读(semi-consistent),增加了update操作的并发
可重复度(RR) MySQL默认隔离界别(历史原因,已提交读级别statement主从复制有bug)  通过MVCC已解决幻读
串行化     不使用

### MMVC

乐观锁的一种,增加三列<b>当前行创建时的版本号、删除时的版本号、回滚指针</b>，版本号递增,查询时比较版本号

### 锁(事务)

- 锁类型有共享锁(S)、排它锁(X)、意向共享(IS)、意向排它(IX)四类,后两者为表锁
-  解决并发问题最有效的方案是引入了锁的机制，锁在功能上分为共享锁(shared lock)和排它锁(exclusive  lock)即通常说的读锁和写锁。当一个select语句在执行时可以施加读锁，这样就可以允许其它的select操作进行，因为在这个过程中数据信息是不会被改变的这样就能够提高数据库的运行效率。当需要对数据更新时，就需要施加写锁了，不在允许其它的操作进行，以免产生数据的脏读和幻读。锁同样有粒度大小，有表级锁(table lock)和行级锁(row lock)，分别在数据操作的过程中完成行的锁定和表的锁定。这些根据不同的存储引擎所具有的特性也是不一样的 
- 2PL 加锁阶段/解锁阶段不交叉
- 快照读不加锁; 当前读除 in share mode加S锁外其余加X锁(含select for update), RR下可能会加间隙锁
- 锁分三类: RecordLock、GapLock、Next-KeyLock;Next-KeyLock=RecordLock+GapLock

### 流程

MySQL主要分为Server层和引擎层，server层主要包含连接器、分析器、优化器、执行器和一个binlog日志模块;redolog为Innodb独有; 引擎层负责数据修改. 当涉及事务时,会记录undolog. 执行流程中涉及了两阶段(prepare、commit)提交

- 查询类流程: 权限校验、查询缓存、分析器、优化器、权限校验、执行器、引擎
- 更新类(事务)流程: 分析器、权限校验、执行器、引擎、undolog、redolog prepare、binlog、redolog commit

### 死锁避免

- 尽量保持资源请求顺序一致
- 轻量级事务
- 优化速度,避免子查询和尽量使用索引

### 性能优化

- 表设计优化、优化sql和索引(适当增加索引,优化SQL)、优化mySQL配置
    - 优先选择符合存储需要的最小的数据类型、避免text\blob
    - 不要使用mysql枚举(修改要alter表)
    - 尽量约束not null、不使用外键约束
    - 使用timestamp而不是date
    - 限制索引数量,一般不超过五个
    - 频繁查询考虑使用覆盖索引
    - 避免使用子查询、多join
    - 超一百万行的批量写,要分多次执行;避免大事务
- 增加缓存(提高热点数据命中率,防止缓存穿透)
- 主从复制-读写分离(写主库,读从库,适用于读多写少场景)
    主从一致性方案
    - 半同步复制/同步双写  降低吞吐
    - 中间件路由方案(记录写key(同步周期内)相关查询路由到主库,不相关查询路由到从库)  中间件昂贵
    - 缓存记录写key法  类似中间件法
- 使用MySQL自带分区表(数据量级达到瓶颈后)
- 垂直拆分(业务相关,即微服务化,将不同服务额表分布在不同的数据库上)
- 水平拆分(数据量级达到瓶颈后,使用水平拆分,优化查询耗时)

### 主从复制

MySQL通过binlog实现主从复制,binlog有三种方式(statement,row,mixed)
statement 
基于sql记录, 节省IO,较少日志量, 但为复现master需要记录上下文信息,且容易因存储过程/函数等因素出现bug
row 
基于行value修改记录,可读清晰,无关存储过程/函数, 但以行为记录单位, 日志量较大
mixed
statement/row结合版本, add/update/delete基于row, 表结构修改等基于statement

### 高可用性

- 提升平均失效时间
  - 最小权限
  - 谨慎升级
  - 确认配置、禁用DNS
  - 一般要禁用查询缓存
  - 避免复杂特性(触发器、复制过滤)
  - 备库只读,避免复制自动启动
  - 及时归档清理,避免硬盘过载、硬盘写满
  - 定期检查复制完成性
- 降低平均恢复时间
- 避免单点故障

### 杂项

- MySQL 应统一使用字符集 utf8mb4
- 登录命令 mysql -h -P -u -p
- innodb_flush_log_at_trx_commit参数指定了redolog的写入机制
  - 0 每次事务提交时都只是把redolog 留在redolog buffer中
  - 1 每次事务提交时都将redolog直接持久化到磁盘
  - 2 每次事务提交时都只是把redolog写到 FS page cache,每秒刷盘
- sync_binlog参数指定了binlog的写入机制(binlog会在事务执行过程中写入到内存bin cache,最后一起写入)
  - 0 每次提交事务都只write(写入到FS page cache),不fsync(刷盘)
  - 1 每次提交事务都write, fsync
  - N 每次提交事务都write, 累计N个事务fsync
- 慢查询原因
  - 偶尔慢: 可能由数据库在持久化redolog(刷脏页)、锁竞争引起
  - 普遍慢: 可能由选择引擎不当、没走索引等引起
- 最左前缀原则、覆盖索引
- 回查机制的存在,可将随机IO转为顺序IO

##     Redis

### 数据结构

String、Hash、List、Set、Zset、Pub/Sub

Pub/Sub 通过订阅和推送可用List实现异步队列(BLPOP)、Zset实现延时队列(score)

### io模型

IO多路复用、单线程避免上下文切换

### 集群策略

主从模式: master节点挂掉后,slave无法自动提升为master,服务不可用
哨兵模式(sentinel): master节点挂掉后,slave自动提升为master,继续提供服务(需要单独配哨兵)
集群模式(cluster): 一般采用3主3从(某个master与其slaves全部挂掉会失去提供服务能力,某一时刻超过半数masters挂掉会失去服务能力(无法选举从节点));master只有宕机,由slaves(随机延迟)发起选举(只有master可投票),raft机制

### 缓存优缺点

优点: 性能高、并发高、主从、持久化
缺点: 缓存与数据库双写一致性、缓存雪崩(缓存集中失效)、缓存击穿(查询不存在数据)、无底洞现象(批操作涉及多次网略请求)、缓存并发竞争

- 一致性: 缓存不保障强一致性,只保障最终一致性, 强一致性场景可采用数据库读写分离等;非强一致,双删策略
- 雪崩: 缓存预热;失效时间加随机数,防止集中失效; 双缓存策略(一个加过期时间,一个不加);本地缓存兜底;服务降级兜底;
- 击穿: 互斥锁策略(限制并发量);布隆过滤(使用bitmap映射查询条件,拦截不合法查询);缓存空对象
- 无底洞: 优化批处理操作,减少通信次数;使用长连接
- 并发写竞争: 使用watch乐观锁(或是独占锁)

### 缓存过期策略

- 定时删除 浪费大量CPU时间(完全依赖定时删除时, 每有过期键就需要扫描)
- 惰性删除 浪费大量内存、可能内存泄漏(当下次使用时检查是否过期)
- 定时+惰性 实际使用方式

### 持久化

rdb(快照模式全量持久化)        save  秒  更新量  rdb快照或恢复都会干掉过期键
rdb在保存快照时会fork出子进程(作主存页拷贝),fork会阻塞主进程(拷贝父进程的所有状态,包括已分配的内存,如果机器不够强,会造成服务延迟)
rdb每次都会生成一个完整的快照文件(之前的快照可删除)
rdb数据恢复比aof快得多
rdb是定期生成的, crash时会造成数据丢失

aof(增量持久化)  always(有写入就同步,最安全) / everysec(每秒同步,折中) / no(由OS决定,速度最快)
安全性高, AOF文件在发生断电等问题时也不会损坏
AOF文件易读、可修改
性能消耗比RDB高
AOF文件比RDB更大(采用auto-aof-rewrite-percentage可重写AOF,剔除失效日志)
数据恢复速度慢

### 数据淘汰策略

noeviction: 不删除,再次存储时返回错误策略
allkeys-lru: 数据集的最近最少使用优先淘汰策略
volatile-lru: 自动过期数据集的最近最少使用优先淘汰策略
allkeys-random: 数据集的随机淘汰策略
volatile-random: 自动过期数据集的随机淘汰策略
volatile-ttl: 自动过期数据集的顺序消亡淘汰策略
volatile-lfu:从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰(4.0+)
allkeys-lfu：当内存不足以容纳新写入数据时,在键空间中,移除最不经常使用的key(4.0+)

### 增加节点

Redis集群保存有hash槽与机器的映射,当添加节点时, 需要通过执行 reshard 重新分配hash槽

### 渐进式hash

在Redis底层数组元素超过一个阈值时,会触发一个Rehash操作(扩容2倍或1/2), 为减少重复扫描和数据遗漏,会进行高位掩码&操作,确定实际的扫描bucket; 渐进式hash不是一次性完成hash, 而是将每个数组空间的转移分摊到各次请求(使得各个请求耗时比较平滑)

<img src='./jNote/rehash.jpg'/>

集群模式下,一个节点对应一个DB,一个DB对应一个dict,一个dict对应两个dictht,正常情况只用到ht[0],ht[1] 在Rehash时使用; 由于Rehash时会重新分配ht[1]内存,会导致内存抖动

### 乐观锁(利用watch实现,事务期间lock_key发生改变,事务不会提交)

watch lock_key

multi

//批量操作

exec

### 分布式锁

参考Redisson, 亦可以使用lua语言自行实现

##     MongoDb

##     杂项

- Redis key-value String 最大512M
- Redis 写丢失场景有异步复制、主从切换
- Redis 集群最大个数即为hash槽的个数(2^14), 采用hash槽利于无损扩容和缩容
- Redis pipeline作用:合并零碎操作,提高效率
- Redis RDB持久化或AOF重写时可能造成内存突增,因此一般要保持25%的余量
- Redis 4.0+的单机qps可达10~20万,tps达10万(一般需要redis-benchmark压测实际量)
- MySQL主从复制的Slave_SQL_Running线程是不能并发的(5.6之后可按组并发)
- MySQL单机并发的三个点: 增加CPU及核数(增加线程并发)、增加缓存、使用磁盘阵列(增加IO并发)
- MySQL主从复制读写分离强一致性可采用半同步复制解决<img src='./jNote/mysqlSemiDump.png'/>
- MySQL主从同步加速(大方面就是使用好硬件,使用万兆网等)
    - slave sync_binlog=0
    - 直接禁用slave binlog=0
    - slave innodb_flush_log_at_trx_commit=2
    - 并行复制(解决slave同步不是并发的问题)
- MySQL InnoDB Log类型
    - Redo Log保证持久性(redo有写入缓冲区,commit的时候肯定刷盘,为保证效率缓冲区每秒也会刷盘[好几个策略];事务提交后数据只是写在了内存脏页,当脏页被刷盘,Redo Log失效,可被覆盖)
    - Undo Log来保证原子性、一致性、MVCC(产生于事务之前,生成MVCC版本数据, 事务提交后Undo不能被立即删除,需要放入待清理链表,由purge线程处理,防止某些大事务读不到数据)
    - binlog 用于主从复制或(基于某些时间点的)数据库还原
    - relay log 中继日志,用于主从复制
    - error log / slow query log / general log
- 

### 缓存过期策略之LRU

使用一个LinkedHashMap, 每次有新的缓存进入,则先映射,若查询得到,则将其挪至表头,然后检查缓存容量是否超过限制, 若不超过则返回,超过则从表尾开始移除数据, 直到缓存在容量许可内(<b style='color:red'>保持热点数据</b>)

### CAP/BASE

- CAP 一致性、可用性、分区容错性 分布式只能由AP(如BASE,由AP改进而来)或CP(如Zookeeper)两种模式;由于不满足P是小概率事件(网络原因),所以大部分时间还是要保证CA的
- BASE  基本可用(允许服务降级)、软状态(允许存在不一致的中间态)、最终一致(补偿至最终一致)
- 2PC 一阶段 所有事务就绪但不提交, 二阶段 所有事务提交或回滚(mysql支持XA事务)
    - A协调者单点问题
    - B同步阻塞问题(并发问题)
    - C二阶段网络通信问题
- 3PC 一阶段CanCommit;二阶段PreCommit;三阶段DoCommit,引入超时自动提交,未解决C问题
- TCC(补偿事务) try/commit/cancel过程类似2PC,但需要根据不同的异常实现回滚,业务强相关,需要防重
- MQ事务 无上述缺点,可重试,但不保证实时性
- Saga事务 类似于TCC,失败后逆向调用补偿方法

# LINUX

## SHELL

- 单引号 强引用,不会做引用计算
- 双引号 弱引用,会对$等引用做解析
- 反引号 表达式,会被解析出结果作为参数的一部分,等价于$()
- 单括号  命令组/命令替换(即表达式)、初始化数组
- 双单括号 用于扩展表达式(C语言规则)如$(($a + $b))
- 单中括号 等价于test(测试判定,支持==,!=,-z,-n；数字的-eq,-gt；文件属性判定 -e,-d等) 单中括号不支持&&、||等操作
- 双中括号 bash关注字，作用强于单中括号，可用作条件判断结构，且支持模式匹配
- 花括号 文件扩展(类似于排比定义)、代码块(匿名函数)、参数替换({后需要空格，此时作用同())、取值
  - ${var:-string}、${var:=string}、${var:+string}、${var:?string} 类似三元运算符(第一个必须是变量)
  - ${var%pattern} 模式匹配 %从后往前匹配 %/#最短匹配  返回删掉匹配串后的结果
  - ${var#pattern} 模式匹配 #从前往后匹配 %/#最短匹配
  - ${var%%pattern} 模式匹配 %从后往前匹配 %%/##最长匹配,无通配符时等价于%/#
  - ${var##pattern} 模式匹配 #从前往后匹配  %%/##最长匹配
- & 后台进程(若启动进程的用户退出,进程会被杀死)
- nohup 不挂断进程(若启动进程的用户退出,进程不会被杀死)
- #!/bin/bash 或#!/bin/sh 脚本第一行,用于指定解析器
- 取变量的几种方式 $Name、${Name}推荐花括号模式
- 局部变量(shell内部有效)/环境标量(shell共享)/shell变量(由shell脚本定义的变量,可以是局部或环境变量); shell定义环境变量可在/etc/profile文件中定义,也可在脚本中使用export 或declare -x 定义
- 字符串长度 ${#Name}、提取子串${Name:start:length}
- 删除数组中元素 unset array[2]
- expr 表达式 加减乘除取余、大小等于、-a-o!与或非、&&||逻辑与或、文件运算符等
- %s、%c、%d、%f printf的格式 字符串(%-10s)、字符、整数(%04d)、浮点数(%-4.2f)
- if then \[elif then\] \[else\] fi
- for var in ();do...done 、while condition do...done、until condition do...done、case、break、continue等

  - for ((i=0; i < 10; i++)); do echo $i; done 
  - for line in $(cat a.txt); do echo $line; done 
  - for f in *.txt; do echo $f; done 
  - while read line ; do echo $line; done < a.txt 
  - cat a.txt | while read line; do echo $line; done
- 骚操作

  - 利用&&||代替ifelse 如: tar -czvf  sean.tar.gz ./sean && echo "TAR OK"||echo "TAR FAIL";
  - find 搭配-exec处理路径  如find . -type f -name "sean*" -exec ls -a {} \; 其中{}代表find的结果,{}与\有空格
  - sh调试  如:sh -x sean.sh; 打印解析过程
  - 字符串替换
    - {str/pattern/replace}替换str第一个匹配的串
    - {str//pattern/replace}替换str所有匹配的串
  - 统计文件大小 stat  -c %s sean.txt 或cat sean.txt|wc -c
  - 去掉空行 |grep -v '^$' 或 |sed '/^$/d' 或 sed '/^\s*$/d'
  - 标准错误输出保存到变量  var=$( (echo 'out'; echo 'error' 1>&2) 2>&1 1>/dev/null)
  - 产生随机数 echo $RANDOM  值域[0, 32676]  或 od -An -N2 -i /dev/[u]random  或
  - 执行root用户的上一个命令 sudo !!
  - vim保存无权写的文件  :w !sudo tee %
  - 打印奇数行  awk 'i=!i' 或 awk 'NR%2' file
  - 实现打印匹配行后的N行  
    - |awk '/pattern/{f=N};--f>=0{print}'
    - |grep -AN "pattern"
    - |sed '/pattern/,+Np'
  - 按行交叉合并文件(多余行以空行匹配) paste -d"\n" $file1 $file2 >$file3 
  - 清理僵尸线程 ps -eal | awk '{ if ($2 == "Z"){ print $4}}' | kill -9
  - 获取ip(内网) ifconfig eth0 |grep "inet addr:" |awk '{print $2}'|cut -c 6-
  - 获取某一行 head -n N|tail -1
  - cat without.log|awk -F '[ ,]' '{for (f=1; f <= NF; f+=1) {if ($f ~ /entity_id/) {print $f}}}'>>sean.data
  - rcp -r work@10.126.107.24:/opt/esearch/  /opt/eseach
- 

## 运维 

### 配置git

## 常用命令

文件相关

- 增 touch mkdir rz/sz
- 删 rm rmdir
- 改 mv cp cat  tar/gzip link
- 查 ls find more/less head/tail which
- 系统
  - netstat -anp 或 netstat -tunlp

- 进程相关 ps top kill 
- 内存相关 free
- 用户相关 chmod chown passwd
- 磁盘相关 df/du [-ah --max-depth=1]

### awk

内置变量: $0 行 | FS 分隔符 | NR(number of record) 行号 | FNR 文件行号 | FILENAME 当前文件 | IGNORECASE 大小写
内置函数: length() split() substr() mktime() systime() 等q
脚本关键字: BEGIN 运行于所有行操作之前 | END 运行于所有行操作结束
运算符: ~ 匹配表达式  | !~ 不匹配表达式
常用属性: -F 指定分隔符 | -v 定义变量 | -f 指定脚本 
语法: awk [选项参数] '[pattern] {script}' var=value files    awk [选项参数] -f scriptfile var=value file
示例: 
awk -W help  打印awk所有属性
awk '{print NR,$0,$1}'  a.txt 打印行号 记录 记录的第一个词
awk '$2 ~/is/  {print NR,$0}'  a.txt  打印记录的第二个词包含/is/的记录的行号 记录
awk 'BEGIN{IGNORECASE =1} /test/'   a.txt  打印所有含有test的行(忽略大小写)
awk -F'[ ,.]' '$3 ~ /t/ {print NR,$3}' a.txt  指定分隔符分割, 按顺序以'[]‘中的分隔符分割(先以' '分割,再以',''分割, 再以'.'分割)
awk -vb='Sean' 'BEGIN{print b}' a.txt
特别的, 数字操作会先触发数字转换(从头开始识别,直到第一个非数字),转不成数字的一律为0

## 系统

### 计算/IO密集

​    计算机任务可分为计算密集型[如解码]和IO密集型[如Web访问].
​    计算密集型CPU使用率较高, 线程数设置为CPU核数(减少线程切换); 计算密集型任务对代码运行效率要求较高, 最好采用C语言编写.
​    IO密集型指CPU使用率低, CPU大部分时间在等待IO操作. 此时可以将线程数设置为2倍的CPU核数, 开发以效率为准.
​    针对不同业务情况, 分析: 1) 高并发, 执行时间短, 线程的核心数可设置为CPU核数+1(减少上下文切换); 2) 并发低, 执行时间长, IO密集, 适当增加线程数[如2倍CPU核数]; 3) 并发低, 执行时间长, 计算密集, 线程的核心数可设置为CPU核数+1(减少上下文切换); 4) 高并发, 执行时间长, 此时关键不在线程池, 而在于整体项目的架构, 可优先考虑缓存(减少IO), 增加服务器(减少并发量), 若IO密集则参考2,若计算密集则参考3

### CPU多级缓存一致性

<img src='./jNote/multiCache.jpg'/>

<table>
<thead>
<tr colspan="2">
<th colspan="1" style="text-align:left">MESI协议状态</th>
<th colspan="1" style="text-align:center">描述(各个Cache相互监听)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">M(Modified)</td>
<td style="text-align:center">数据有效,仅存在于本Cache,且被修改</td>
</tr>
<tr>
<td style="text-align:left">E(Exclusive)</td>
<td style="text-align:center">数据有效,仅存在于本Cache</td>
</tr>
<tr>
<td style="text-align:left">S(Shared)</td>
<td style="text-align:center">数据有效,存在于多个Cache</td>
</tr>
<tr>
<td style="text-align:left">I(Invalid)</td>
<td style="text-align:center">数据无效(其他Cache修改导致)</td>
</tr>
</tbody>
</table>

### PageCache机制

page cache是OS的文件缓存,用于加速对文件的读写

#### 文件读取

第一次读文件未命中pache cache,OS从磁盘读取所需数据时,会对后续数据进行预读取,从而在下次顺序读时命中page cache, 读取速度基本等同于内存

#### 文件写入

OS会将数据先写入page cache,随后通过异步的方式由pdflush内核线程将数据刷盘至物理磁盘,亦可强制刷盘

缺点 脏页回写,内存回收,内存swap会造成延迟

## Nginx



# 算法

##     数据结构

##     多指针

## 位运算

### bitmap数据筛选[布隆过滤原理]

一般筛选用户信息会使用一张表,表中包含各种属性信息，但随着需求统计的属性越来越多(上千), 不但需要修改表结构, 且等到筛选条件越来越多时,SQL过长,且需要distinct等操作, 数据库性能将会成为瓶颈.
利用bitmap和倒排索引建立用户与索引(就是一个long型ID)的关联关系, 然后每个属性都对应一张表, 每个属性的值域的枚举值都是一条记录(增加一个全值域的记录)[如拥有手机类型的值域枚举就是Apple/华为等,全值域记录就是所有值域枚举的bitmap的|], 对应的bitmap字段就是拥有此项枚举值的用户索引的bitmap, 当需要筛选时只需取出对应bitmap作交叉操作(支持&,|),取反(!)操作需要与全局bitmap异或

##     动态规划

## 深搜/广搜

##     排序

#### 冒泡

```java
public static void bubbleSort(int[] nums){
    if(nums==null)return;
    for(int i=nums.length-1;i>0;i--){
        boolean watch=false;
        for(j=0;j<i;j++){
            if(nums[j]>nums[j+1]){
                swap(nums,j,j+1);
                watch=true;
            }
        }
        if(!watch)return;
    }
}
```

#### 插入

```java
public static void insertSort(int[] nums){
    if(nums==null)return;
    for(int i=1;i<nums.length;i++){
        int temp=nums[i];
        int j;
        for(j=i-1;j>=0 && temp<nums[j];j--){
            nums[j+1]=nums[j];
        }
        nums[j+1]=temp;
    }
}
```

#### 选择

```java
public static void selectSort(int[] nums){
    if(nums==null)return;
    for(int i=0;i<nums.length-1;i++){
        int min=i;
        for(int j=i+1;j<nums.length;j++){
            min=nums[min]>nums[j]?j:min;
        }
        if(i!=min)swap(nums,i,min);
    }
}
```

#### 快排

```
public static void quickSort(int[] nums){
    if(nums==null || nums.length<2)return;
    quick(nums,0,nums.length-1);
}
private static void quick(int[] nums,int begin,int end){
    int judge=nums[begin];
    int bKeeper=begin;
    int eKeeper=end;
    while(begin<end){
        while(end>begin && nums[end]>=judge)end--;
        nums[begin]=nums[end];
        while(end>begin && nums[begin]<=judge)begin++;
        nums[end]=nums[begin];
    }
    nums[begin]=judge;
    if(bKeeper<begin-1){
    	quick(nums,bKeeper,begin-1);
    }
    if(eKeeper>begin+1){
    	quick(nums,begin+1,eKeeper);
    }
}
```

#### 归并

```java
public static mergeSort(int[] nums){
    if(nums==null || nums.length<2)return;
    device(nums,0,nums.length-1);
}
private static void device(int[] nums,int begin,int end){
    if(begin<end){
    	int mid=(begin+end)/2;
        device(nums,begin,mid);
        device(nums,mid+1,end);
        merge(nums,begin,mid+1,end);
    }
}
private static void merge(nums,int begin,int mid,int end){
    int[] temp=new int[end-begin+1];
    int idx=0;
    int midTemp=mid;
    int beginTemp=begin;
    while(beginTemp<mid && midTemp<=end){
        if(mums[beginTemp]<nums[midTemp]){
            temp[i++]=nums[beginTemp++];
        }else{
            temp[i++]=nums[midTemp++];
        }
        while(beginTemp<mid){
            temp[i++]=nums[beginTemp++];
        }
        while(midTemp<=mid){
            temp[i++]=nums[midTemp++];
        }
    }
    i=0;
    while(begin<=end){
        nums[begin++]=temp[i++];
    }
}
```

#### 堆排

```java
public static void heapSort(int[] nums){
    if(nums==null || nums.length<2)return;
    buildHeap(nums);
    for(int i=nums.length-1;i>0;i--){
        swap(nums,0,i);
        heapify(nums,i,0);
    }
}
private static void buildHeap(int[] nums){
    int ldx=(nums.length-2)>>1;
    for(int i=idx;i>=0;i--){
        heapify(nums,nums.length,i);
    }
}
private static heapify(int[]  nums,int end,int cdx){
    int leftC=(cdx<<1)+1;
    int rightC=leftChild+1;
    int mdx=cdx;
    if(leftC<end && nums[leftC]>nums[cdx])mdx=leftC;
    if(rightC<end && nums[rightC]>nums[cdx])mdx=rightC;
    if(mdx!=cdx){
        swap(nums,cdx.mdx);
        heapify(nums,end,mdx);
    }
}
```

#     缓存

## **外存：**

　　也就是我们经常说的（CDEF盘的大小）外储存器是指除计算机内存及CPU缓存以外的储存器，此类储存器一般断电后仍然能保存数据。常见的外存储器有硬盘、软盘、光盘、U盘等，一般的软件都是安装在外存中

## **内存：**

　　内存是计算机中重要的部件之一，它是与CPU进行沟通的桥梁。计算机中所有程序的运行都是在内存中进行的，因此内存的性能对计算机的影响非常大。内存(Memory)也被称为内存储器，其作用是用于暂时存放CPU中的运算数据，以及与硬盘等外部存储器交换的数据。只要计算机在运行中，CPU就会把需要运算的数据调到内存中进行运算，当运算完成后CPU再将结果传送出来，内存的运行也决定了计算机的稳定运行，此类储存器一般断电后数据就会被清空

## **高速缓存：**

　　高速缓存是用来协调CPU与主存之间存取速度的差异而设置的。一般情况下，CPU的工作速度高，但内存的工作速度相对较低，为了解决这个问题，通常使用高速缓存，高速缓存的存取速度介于CPU和主存之间。系统将一些CPU在近几个时间段经常访问的内容存入高速缓冲，当CPU需要使用数据时，先在高速缓存中找，如果找到，就不必访问内存了，找不到时，再找内存，这样就在一定程度上缓解了由于主存速度低造成的CPU“停工待料”的情况



## Java中常用缓存

1. map集合

2. spring框架的缓存 实现步骤：　

   　　第一步： 导入spring-boot-starter-cache模块

   ```
   <dependency>
       <groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-starter-cache</artifactId>
   </dependency>
   ```

   ​    第二步： @EnableCaching开启缓存

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   @SpringBootApplication
   @EnableCaching
   public class Springboot07CacheApplication {
   
      public static void main(String[] args) {
         SpringApplication.run(Springboot07CacheApplication.class, args);
      }
   }
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ​    第三步： 使用缓存注解

      UserInfoCacheController

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   import org.springframework.beans.factory.annotation.Autowired;
   import org.springframework.cache.annotation.CacheEvict;
   import org.springframework.cache.annotation.CachePut;
   import org.springframework.context.annotation.Scope;
   import org.springframework.stereotype.Controller;
   import org.springframework.web.bind.annotation.RequestMapping;
   import org.springframework.web.bind.annotation.RequestMethod;
   import org.springframework.web.bind.annotation.RequestParam;
   import org.springframework.web.bind.annotation.ResponseBody;
   import www.mxh.com.usercache.dao.LoginMapper;
   import www.mxh.com.usercache.entity.UserInfo;
   import www.mxh.com.usercache.service.Impl.LoginServiceImpl;
   
   @Scope("prototype")
   @Controller
   public class UserInfoCacheController {
   
       @Autowired(required = true)
       private LoginMapper loginMapper;
   
       @Autowired
       private LoginServiceImpl loginService;
   
       @ResponseBody
       @RequestMapping(value = "/user/cache/login",method = RequestMethod.GET)
       public void userLoginByCache(String username,String password){
           UserInfo userInfo = loginService.UserLoginByCache(username, password);
           System.out.println(userInfo);
       }
   
       /**
        * 通过username删除单个用户缓存信息
        * @param username
        */
       @CacheEvict(value="userInfo",key="#username")
       @ResponseBody
       @RequestMapping(value = "/user/cache/delete",method = RequestMethod.GET)
       public void deleteUserInfoCache(String username) {
           System.out.println("清除用户信息缓存");
       }
   
       /*@Cacheable(value="userInfo",key="#username")
       @ResponseBody
       @RequestMapping(value = "/user/cache/select",method = RequestMethod.GET)
       public UserInfo selectUserInfoCache(String username) {
           System.out.println("清除用户信息缓存");
       }*/
   
       /**
        * 通过username修改单个用户缓存信息
        * @param username
        * @param password
        * @param age
        * @param sex
        * @param user_id
        * @return
        */
       @CachePut(value="userInfo",key = "#username")
       @ResponseBody
       @RequestMapping(value = "/user/cache/update",method = RequestMethod.GET)
       public UserInfo updateUserInfoCache(@RequestParam(required = false) String username,
                                           @RequestParam(required = false) String password,
                                           @RequestParam(required = false) Integer age,
                                           @RequestParam(required = false) String sex,
                                           @RequestParam(required = false) Long user_id) {
           UserInfo userInfo = loginMapper.updateUserInfoById(username, password, age, sex, user_id);
           System.out.println("1.更新用户缓存信息: " + userInfo);
           if(null == userInfo){
               userInfo = loginMapper.selectUserByUsernameAndPassword(username,password);
           }
           System.out.println("2.更新用户缓存信息: " + userInfo);
           return userInfo;
       }
   
   }
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   　　

   ```
    LoginServiceImpl
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   import org.springframework.beans.factory.annotation.Autowired;
   import org.springframework.cache.annotation.CacheConfig;
   import org.springframework.cache.annotation.Cacheable;
   import org.springframework.stereotype.Service;
   import www.mxh.com.usercache.dao.LoginMapper;
   import www.mxh.com.usercache.entity.UserInfo;
   import www.mxh.com.usercache.service.LoginService;
   import www.mxh.com.usercache.util.UserCacheManager;
   /*定义缓存名称*/
   @CacheConfig(cacheNames = "userInfo")
   @Service
   public class LoginServiceImpl implements LoginService {
   
       @Autowired(required = true)
       private LoginMapper loginMapper;
   　　　    /*将查询到的数据放入缓存，下次调用该方法会先去缓存中查询数据*/　
       @Cacheable(value = "userInfo", key = "#username")
       @Override
       public UserInfo UserLoginByCache(String username, String password) {
           UserInfo userInfo = loginMapper.selectUserByUsernameAndPasswordWithCache(username, password);
           System.out.println("用户缓存信息: " + userInfo);
           return userInfo;
       }
   }
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   　　

   ```
    LoginMapper
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   import org.apache.ibatis.annotations.Param;
   import org.apache.ibatis.annotations.Select;
   import org.springframework.stereotype.Repository;
   import www.mxh.com.usercache.entity.UserInfo;
   
   /**
    * 登陆dao层操作接口
    */
   @Repository
   public interface LoginMapper{
   
       @Select("select * from user_info where username=#{username} and password=#{password}")
       UserInfo selectUserByUsernameAndPassword(@Param("username") String username,
                                                @Param("password") String password);
   
       @Select("select * from user_info where username=#{username} and password=#{password}")
       UserInfo selectUserByUsernameAndPasswordWithCache(@Param("username") String username,
                                                         @Param("password") String password);
   
       @Select("update user_info set username=#{username},password=#{password},age=#{age},sex=#{sex} where user_id=#{user_id}")
       UserInfo updateUserInfoById(@Param("username") String username,
                                   @Param("password") String password,
                                   @Param("age") int age,
                                   @Param("sex") String sex,
                                   @Param("user_id") long user_id);
   
       /*@Select("insert into user_info (username,password,age,sex,user_id) values(#{username},#{password},#{age},#{sex},#{user_id})")
       UserInfo saveUserInfo(@Param("username") String username,
                             @Param("password") String password,
                             @Param("age") int age,
                             @Param("sex") String sex,
                             @Param("user_id") long user_id);*/
   
   }
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
    UserInfo（实体类） 
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   import java.io.Serializable;
   import java.util.Date;
   
   public class UserInfo implements Serializable {
   
       private static final long serialVersionUID = 1L;
   
       private Long user_id;
   
       private String username;
   
       private String password;
   
       private String sex;
   
       private Integer age;
   
       private Date login_time;
   
       public Long getUser_id() {
           return user_id;
       }
   
       public void setUser_id(Long user_id) {
           this.user_id = user_id;
       }
   
       public String getUsername() {
           return username;
       }
   
       public void setUsername(String username) {
           this.username = username;
       }
   
       public String getPassword() {
           return password;
       }
   
       public void setPassword(String password) {
           this.password = password;
       }
   
       public String getSex() {
           return sex;
       }
   
       public void setSex(String sex) {
           this.sex = sex;
       }
   
       public Integer getAge() {
           return age;
       }
   
       public void setAge(Integer age) {
           this.age = age;
       }
   
       public Date getLogin_time() {
           return login_time;
       }
   
       public void setLogin_time(Date login_time) {
           this.login_time = login_time;
       }
   
       @Override
       public String toString() {
           return "UserInfo{" +
                   "user_id=" + user_id +
                   ", username='" + username + '\'' +
                   ", password='" + password + '\'' +
                   ", sex='" + sex + '\'' +
                   ", age=" + age +
                   ", login_time=" + login_time +
                   '}';
       }
   }
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

    

   　 application.properties

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   server.port=8009
   spring.datasource.url=jdbc:mysql://localhost:3306/bank?useUnicode=true&characterEncoding=utf8
   spring.darasource.username=root
   spring.datasource.password=root
   spring.datasource.driver-class-name=com.mysql.jdbc.Driver
   # 目标缓存管理器
   #spring.cache.type=SIMPLE
   spring.cache.type=ehcache
   spring.cache.ehcache.config=classpath:ehcache.xml
   # 打印sql语句
   logging.level.www.mxh.com.usercache.dao=debug
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
    ehcache.xml
   ```

   [![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

   ```
   <ehcache>
   
       <!--
           磁盘存储:将缓存中暂时不使用的对象,转移到硬盘,类似于Windows系统的虚拟内存
           path:指定在硬盘上存储对象的路径
           path可以配置的目录有：
               user.home（用户的家目录）
               user.dir（用户当前的工作目录）
               java.io.tmpdir（默认的临时目录）
               ehcache.disk.store.dir（ehcache的配置目录）
               绝对路径（如：d:\\ehcache）
           查看路径方法：String tmpDir = System.getProperty("java.io.tmpdir");
        -->
       <diskStore path="java.io.tmpdir" />
   
       <!--
           defaultCache:默认的缓存配置信息,如果不加特殊说明,则所有对象按照此配置项处理
           maxElementsInMemory:设置了缓存的上限,最多存储多少个记录对象
           eternal:代表对象是否永不过期 (指定true则下面两项配置需为0无限期)
           timeToIdleSeconds:最大的发呆时间 /秒
           timeToLiveSeconds:最大的存活时间 /秒
           overflowToDisk:是否允许对象被写入到磁盘
           说明：下列配置自缓存建立起600秒(10分钟)有效 。
           在有效的600秒(10分钟)内，如果连续120秒(2分钟)未访问缓存，则缓存失效。
           就算有访问，也只会存活600秒。
        -->
       <defaultCache maxElementsInMemory="10000" eternal="false"
                     timeToIdleSeconds="600" timeToLiveSeconds="600" overflowToDisk="true" />
   
       <!--类中的缓存空间须在该文件中配置-->
       <cache name="userInfo" maxElementsInMemory="10000" eternal="false"
              timeToIdleSeconds="120" timeToLiveSeconds="600" overflowToDisk="true" />
   
   </ehcache>
   ```



##     Guava cache  

### 一、简介

缓存的优势：

1、减少网络传输的开销

2、减少数据序列化和反序列化

3、加快了访问速度(与数据库、文件系统相比)。

缓存的使用场景：

1、缓存全量数据

2、缓存热点数据

### 二、基本用法

1、缓存加载

这两种方法都实现一种逻辑：从缓存中取key的值,如果该key已经缓存过,直接返回缓存中的值,

如果没有缓存该key,可以通过某个方法来获取这个值。

- CacheLoader
- Callable

3、缓存回收

    基于容量回收
    
    CacheBuilder.maxmumSize(long)
    
    基于时间回收
    
    CacheBuilder.expireAfterAccess()
    
    CacheBuilder.expireAfterWrite()
    
    基于引用回收
    
    软引用和弱引用
    
    CacheBuilder.weakKeys()
    
    当键没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用键的缓存用==而不是equals比较键。
    
    CacheBuilder.weakValues()
    
    CacheBuilder.softValues()
    
    软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。使用软引用时需要考虑性能影响。使用软引用值的缓存同样用==而不是equals比较值。
引用类型
	

描述
	

回收时间
	

用途
	

备注

强引用
	

程序中随处可见
	

永不回收
	

普通对象引用
	

 

软引用
	

描述对象有用但不是必须的
	

内存不足回收
	

缓存对象
	

软引用可以和一个引用队列(ReferenceQueue)联合使用，如果软引用所引用的对象被垃圾回收器回收，java虚拟机就会把这个软引用加入到与之关联的引用队列中

弱引用
	

描述对象不是非必须的
	

jvm垃圾回收
	

缓存对象



三、缓存回收原理及实现

1、什么是LRU算法

LRU(Least recently used,最近最少使用)是核心思想是基于“如果数据最近被访问过，那将来被访问的几率也更高”。

1.1：新数据插入到链表的头部。

1.2：每当缓存命中(即缓存数据被访问)，则将数据移到链表头部。

1.3: 当链表满的时候，将链表尾部的数据丢弃。

 

2、LocalCache数据结构

 

名称
	

类型
	

作用

segments
	

Segment<k,V>[]
	

实现ReentrantLock锁，减少锁的粒度，提高并发度。好处：分段锁很好保证并发读写的效率，因此支持非阻塞的读和不同段之间的并发写

table
	

AtomicReferenceArray<ReferenceEntry<K,V>
	

存放键值对的地方

referenceEntry
	

ReferenceEntry<K,V>
	

封装键值对

keyReferenceQueue
	

ReferenceQueue<K>
	

已经被GC，需要内部清理key引用队列

valueReferenceQueue
	

ReferenceQueue<V>
	

已经被GC，需要内部清理value引用队列

recencyQueue
	

Queue<ReferenceEntry<K,V>>
	

记录当entries被访问时，去更新accessQueue中顺序。在segment中当segment上限值或是写操作发生会去更新accessQueue顺序，同时清空recencyQueue。

writeQueue
	

Queue<ReferenceEntry<K,V>>
	

按照写入时间进行排序的元素队列，写入元素时会把它加入队列的队尾

accessQueue
	

Queue<ReferenceEntry<K,V>>
	

按照访问时间进行排序的元素队列，访问或是写入元素时会把它加入到队列的队尾。

3、segment如何清理(evict) entry

evict方式

使用cacheBuilder构建的缓存不会“自动”执行清理和回收工作，也不会在某个缓存项过期后马上清理。

相反，它会在写操作时顺带做少量的维护工作，或者偶尔在读操作时做——如果写操作实在太少的话。

理由：如果guava使用开启一个后台线程每隔一段时间来扫描一次table以evict哪些已经expire的entry，

这样的增加资源的消耗。

evict对象

基于引用回收

keyReferenceQueue

valueReferenceQueue

基于时间回收

writeQueue

accessQueue

 

evict流程

基于引用和时间回收策略

put开始时

 

get结束之前

 

基于容量回收策略(LRU)

put结束之前

前提条件：在设置maxmumSize或maximumWeight时，才会进行该操作。

weight的作用

1. 对weight值为0时，在计算因为size limit而evict是忽略该Entry（它可以通过其他机制evict）。

2. 如果设置了maximumWeight值，则当Cache中weight和超过了该值时，就会引起evict操作。


### **三、缓存刷新**

> 在Guava cache中支持定时刷新和显式刷新两种方式，其中只有LoadingCache能够进行定时刷新。

**定时刷新**

> 在进行缓存定时刷新时，我们需要指定缓存的刷新间隔，和一个用来加载缓存的CacheLoader，当达到刷新时间间隔后，下一次获取缓存时，会调用CacheLoader的load方法刷新缓存。例如构建个刷新频率为10分钟的缓存:

```
CacheBuilder.newBuilder()
        // 设置缓存在写入10分钟后，通过CacheLoader的load方法进行刷新
        .refreshAfterWrite(10, TimeUnit.SECONDS)
        // jdk8以后可以使用 Duration
        // .refreshAfterWrite(Duration.ofMinutes(10))
        .build(new CacheLoader<String, String>() {
            @Override
            public String load(String key) throws Exception {
                // 缓存加载逻辑
                ...
            }
        });
 
```

**显式刷新**

> 在缓存构建完毕后，我们可以通过Cache提供的一些借口方法，显式的对缓存进行刷新覆盖，例如：

```
// 构建一个缓存
Cache<String, String> cache = CacheBuilder.newBuilder().build();
// 使用put进行覆盖刷新
cache.put("k1", "v1");
// 使用Map的put方法进行覆盖刷新
cache.asMap().put("k1", "v1");
// 使用Map的putAll方法进行批量覆盖刷新
Map<String,String> needRefreshs = new HashMap<>();
needRefreshs.put("k1", "v1");
cache.asMap().putAll(needRefreshs);
// 使用ConcurrentMap的replace方法进行覆盖刷新
cache.asMap().replace("k1", "v1");
```

> 对于LoadingCache，由于它能够自动的加载缓存，所以在进行刷新时，不需要显式的传入缓存的值：

```
LoadingCache<String, String> loadingCache = CacheBuilder
            .newBuilder()
            .build(new CacheLoader<String, String>() {
                @Override
                public String load(String key) throws Exception {
                    // 缓存加载逻辑
                    return null;
                }
            });
// loadingCache 在进行刷新时无需显式的传入 value
loadingCache.refresh("k1");
```

# Redis 

## 哨兵原理

https://www.cnblogs.com/Eugene-Jin/p/10819601.html



# Hiredis-v

https://github.com/vipshop/hiredis-vip/

常用的同步API主要有：

redisContext *redisConnect(const char *ip, int port);
void *redisCommand(redisContext *c, const char *format, ...);
void freeReplyObject(void *reply);

**第1讲 连接redis数据库**

函数redisConnect被用来创建一个  redisContext。这个context是hiredis持有的连接状态。redisConnect结构体有一个整型的err变量来标识连接错误码，如果连接错误则为非零值。变量errstr标识连接结果的文字描述。更多这方面的信息会在以下Errors章节说明。当你使用 redisConnect 来创建连接时应该检查err变量来判断是否连接正常建立。



>  redisContext *c = redisConnect("127.0.0.1", 6379);
>  if (c != NULL && c->err) {
>  printf("Error: %s\n", c->errstr); // handle error }

**第2讲 发送命令到redis**

```
首先介绍redisCommand。此函数类似于printf的使用方式，如
```



>  reply = redisCommand(context, "SET foo bar");

类似于printf的s%格式化方式，如

>  reply = redisCommand(context, "SET foo %s", value);

当你需要发送二进制安全的命令时，可以采用%b的格式化方式，同时需要一个**字符串指针**和**size_t类型的字符串长度参数**,如下

>  reply = redisCommand(context, "SET foo %b", value, (size_t) valuelen);

在API内部，Hiredis根据不同的参数分割命令，将其转化为“操作redis数据库的标准命令”，你可以格式化多个参数来构造redis的命令，如下

```
reply = redisCommand(context, "SET key:%s %s", myid, value);
```

**第3讲  处理redis应答**

当命令被成功执行后，redisCommand会有相应的返回值。如果有错误发生，返回值为NULL或者redisReply结构体中的err变量将会被设置成相应的值（请参照Errors章节）。一旦有错误发生，context不能被重用，并且你需要建立一个新的连接。

redisCommand执行后返回值类型为redisReply。通过redisReply结构体中的type变量，可以确定命令执行的情况。



-  REDIS_REPLY_STATUS：
  -  返回执行结果为状态的命令。比如set命令的返回值的类型是REDIS_REPLY_STATUS，然后只有当返回信息是"OK"时，才表示该命令执行成功。可以通过reply->str得到文字信息，通过reply->len得到信息长度。
-  REDIS_REPLY_ERROR：
  -  返回错误。错误信息可以通过reply->str得到文字信息，通过reply->len得到信息长度。
-  REDIS_REPLY_INTEGER：
  -  返回整型标识。可以通过reply->integer变量得到类型为long long的值。
-  REDIS_REPLY_NIL:
  -  返回nil对象，说明不存在要访问的数据。
-  REDIS_REPLY_STRING:
  -  返回字符串标识。可以通过reply->str得到具体值，通过reply->len得到信息长度。
-  REDIS_REPLY_ARRAY:
  -  返回数据集标识。数据集中元素的数目可以通过reply->elements获得，每个元素是个redisReply对象，元素值可以通过reply->element[..index..].*形式获得，用在获取多个数据结果的操作。

注意1：  执行完命令调用后，应该通过freeReplyObject()释放redisReply。对于嵌套对象（比如数组）要注意，并不需要嵌套进行释放，若进行嵌套释放，会造成内存破坏。

注意2:  hiredis当前版本(0.10.0)在使用异步API时，会自己释放replies对象。这意味着，你使用异步API时并不需要主动调用freeReplyObject，relpy对象在回调返回时将会被自动释放。但是这种行为也许会在将来的版本中改变，所以升级时请密切关注升级日志。

**第4讲  清理连接资源**

断开连接并且释放context使用以下函数

void redisFree(redisContext *c);

此函数立马关闭socket并且释放创建context时分配的资源。

**第5讲  发送多个命令参数**

和redisCommand函数相似，redisCommandArgv函数可以用于传输多个命令参数。函数原型为

void *redisCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen);

类似于 lpush， del key1 key2..., zadd key  score1 member1 score2 member2...这类命令， 其中 argc是传递参数的个数，  argv主要用于传递的string的value, 而argvlen 是每个string的size。



此函数返回值与redisCommand相似。参考https://gist.github.com/dspezia/1455082

**第6讲 管道(PipeLine)**

为了搞清楚Hiredis在**阻塞连接**下的**管线操作**，需要理解其内部执行过程。(context的输出缓冲区中是命令，其输入缓冲区中是reply)。

当任何类似于redisCommand的函数被调用，Hiredis首先将命令格式化为redis支持的命令协议。被格式化后的命令被放入**context的输出缓冲区**，这个缓冲区是动态的，所以它可以容纳任意数量的命令。在命令进入**输出缓冲区**后，redisGetReply 函数被调用，这个函数有以下两种执行方式：

1.  输入缓冲区非空：
   -  从输入缓冲区中尝试解析单独的reply对象并且返回reply
   -  如果没有reply能被解析，执行步骤2
2.  输入缓冲区为空：
   -  将整个输出缓冲区写入socket
   -  从socket中读取数据直到有一个reply能被解析

Hiredis为了有效利用socket还提供了redisGetReply的接口。对于管线命令，需要完成的唯一事情就是填充输出缓冲区。有两个函数被用于执行此操作，这两个函数基本与redisCommand函数功能类似，但是他们不返回reply，

>  void redisAppendCommand(redisContext *c, const char *format, ...);
>  void redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen);

当这两个函数被一次或多次调用时，通过redisGetReply依次返回replies。redisGetReply的返回值要么是REDISOK或是REDISERR，REDIS_ERR意味着获得reply发生了错误，想要得到具体的错误原因可以通过err变量来获取。

以下通过一个简单例子说明管线的使用：

>  redisReply *reply;
>  redisAppendCommand(context,"SET foo bar");
>  redisAppendCommand(context,"GET foo");
>  redisGetReply(context,&reply); // reply for SET
>  freeReplyObject(reply);
>  redisGetReply(context,&reply); // reply for GET
>  freeReplyObject(reply);

redisGetReply这个API也可以被用来实现**阻塞的订阅模式**

>  reply = redisCommand(context,"SUBSCRIBE foo");
>  freeReplyObject(reply);
>  while(redisGetReply(context,&reply) == REDIS_OK) 
>  {
>  // consume message
>  freeReplyObject(reply);
>  }

**第7讲 redis常见操作的errors**

第7.1 节

如果redisConnect调用不成功，函数返回值为NULL或者REDIS_ERR，此时context结构体中的err成员为非零值，可能为以下几种常量：

-  REDIS_ERR_IO:当创建连接时（试着写socket或者读socket）发生的I/O错误。如果你在代码中包含了errno.h头文件，你便能得到准确的错误码。
-  REDIS_ERR_EOF:redis服务端已经关闭了此连接。
-  REDIS_ERR_PROTOCOL:服务端解析协议时发生了错误。
-  REDIS_ERR_OTHER:其他错误。目前仅仅表示无法解析目标主机名的错误。

在错误情况下，可以通过context结构体中的errstr成员得到错误的确切描述。

第7.2节

如果redisCommand调用不成功，详情参考第4讲。

**第三部分 异步API**

Hiredis自带的异步API很容易和一些**基于事件的库**结合使用，比如和libev、ibevent的结合使用。

**第1讲 建立hiredis异步连接**

函数redisAsyncConnect被用来和redis建立**非阻塞连接**。它返回redisAsyncContext的结构体，结构体的err成员用来检查在创建连接的过程中是否发生了错误。因为创建的是**非阻塞的连接**，内核并不能立马返回一个连接指定主机的结果。

redisAsyncContext *c = redisAsyncConnect("127.0.0.1", 6379);
if (c->err) 
{
printf("Error: %s\n", c->errstr);
// handle error
}

异步Context可设置一个响应断开连接事件的回调函数，当连接断开时会相应执行。回调函数的原型为

void(const redisAsyncContext *c, int status);

在断开连接的情况下，若连接是由用户自己断开的，则status参数为REDISOK；若出现了其他错误，则status参数为REDISERR，通过err成员可以得到准确的错误码。当回调执行完毕后，context对象会自己释放资源。此事件的回调函数为你创建一个新连接提供了便利。

一个context对象仅能设置一次断开连接的回调，如果再进行下一次设置，将会返回REDIS_ERR。设置断开连接回调函数的原型为：

int redisAsyncSetDisconnectCallback(redisAsyncContext *ac, redisDisconnectCallback *fn);

**第2讲 异步发送操作命令并且响应回调事件** 



在异步的情况下，redis的操作指令将会被自动加入事件循环队列。由于发送命令执行的过程是异步的，当命令执行完毕后，将会调用相应的回调函数。回调函数的原型为

>  void(redisAsyncContext *c, void *reply, void *privdata);

privdata参数是由调用者自己定义的数据类型。

以下是进行异步命令操作的函数：

>  int redisAsyncCommand(redisAsyncContext *ac, redisCallbackFn *fn, void *privdata,const char *format, ...);   int redisAsyncCommandArgv( redisAsyncContext *ac, redisCallbackFn *fn, void *privdata, int argc, const char **argv, const size_t *argvlen);

命令的使用方式和上面所讲的同步接口类似。执行成功返回REDIS_OK，否则返回REDIS_ERR。比如连接已经关闭的情况下再使用redisAsyncCommand向此连接执行命令，就会返回REDIS_ERR。

回调执行完毕后，如果reply不为空，将自动对reply的资源进行回收。当context发生错误时，回调得到的reply将为空。

**第3讲 断开异步连接** 

void redisAsyncDisconnect(redisAsyncContext *ac);

当这个函数被调用时，连接并不会被立即关闭，而是等待所有这个连接的异步命令操作执行完毕，并且回调事件已经执行完毕后，才关闭此连接，这时在响应关闭连接事件的回调函数中得到的状态为REDIS_OK，此连接的资源也将会被自动回收。

**第4讲  将其挂接到事件库X**

在context对象被创建后，进行很少的几步操作，就可以进行挂接。参看目录adapters/下是如何挂接到libev 和 libevent下的。

**第5讲  应答解析API**

Hiredis自带的答复解析API ，可以很容易与更高层次的语言进行绑定。

Esearch：

http://iwiki.58corp.com/wiki/ecomrd/view/%E5%B7%A5%E7%A8%8B%E5%B9%B3%E5%8F%B0%E9%83%A8/5%E3%80%81%E4%B8%9A%E5%8A%A1%E5%9B%BE%E8%B0%B1/LEGO/%E7%B3%BB%E7%BB%9F/01%E3%80%81LEGO%E7%B4%A2%E5%BC%95%E7%B3%BB%E7%BB%9F/esearch%E6%97%A5%E5%BF%97%E8%AF%B4%E6%98%8E/



# SED

```
删除shell变量表示的行号（配合for等语句使用）

    sed -i "${var1},${var2}d" filename		# 这里引号必须为双引号

    


删除包含"xxx"的行
sed -i '/xxx/d' filename
```

# 其他

堆污染：

java中，当一个可变泛型参数指向一个无泛型参数时，堆污染（Heap Pollution）就有可能发生。可能会导致ClassCastException 的发生。

 常见的缓存问题有以下几点 

- 缓存与数据库双写不一致
- 缓存雪崩
- 缓存穿透
- 缓存并发竞争



反作弊问题：

1. springboot3 访问不了静态资源
2. springboot3引入log4j2.xml  解决方案https://www.cnblogs.com/keeya/p/10101547.html
3. 

索引:http://ishare.58corp.com/#/articleDetail?id=1443

topN的计算 方式：

参与二次打分的计算公式在老版本中为：segment段数*(固定值100 + query.size) * 分片数；升级内核后会变为：segment段数*(max(start+rows, primarySortCount)) * 分片数；老版本配置的primarySortCount没有生效，本次升级后会生效，为了保证和原线上逻辑保持一致，本次将修改配置中的primarySortCount值，从1000修改为200；修改逻辑为：原固定值100 + query.size最大为200

- - - - - - - - - - - - - - -



插件的redis：

配置在searcher/package下redisConfig中,如需修改修改后重启searcher,当前依然是线上配置

linux日志： core文件（）



https://www.cnblogs.com/chengliangsheng/p/3597010.html



https://mp.weixin.qq.com/s?__biz=MzI1NDc5MzIxMw==&mid=2247487630&idx=1&sn=ba19b560f0fd8501171317b9a1d0587b&chksm=ea3e941cdd491d0a9436fa67b1bb5570f48e8e68de8e8792b0e940c8dcc4fb04c067a19e5559&mpshare=1&scene=1&srcid=04097xkiT0UdB5RqyTZRbM71&sharer_sharetime=1586402167949&sharer_shareid=3fecbb022f35658e2a5b1d7ec62f9361&key=22d6e5d1c04a357587e3463fb9eb9bbefb632b0521c82cc33bf528670386dd03b97b14bda8dbb88295f325ef76b226824ce017ba4f2847aa45fa2ec2c605712db31bbbe04f7b62d261646238e34794f2&ascene=1&uin=MjM2MDQ0MzIyNQ%3D%3D&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=A%2BFxe1Ng6WS1%2BkYAwt5x7b8%3D&pass_ticket=lv%2FHJ8HLh8yxpdcM4xICqLmUZKsUXBG0JybtJGDrJulUZu15cx1keYicTyxn4SG%2B

![image-20200407192407262](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200407192407262.png)





![image-20200415130730034](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130730034.png)



![image-20200415130842997](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130842997.png)



![(C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130535320.png)

![(C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130556562.png)

![image-20200415130644681](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130644681.png)

![image-20200415130919583](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415130919583.png)

![image-20200415131024483](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415131024483.png)



![image-20200415131002008](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415131002008.png)

![image-20200415131041365](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415131041365.png)

![image-20200415131055981](C:\Users\liulingfeng01\AppData\Roaming\Typora\typora-user-images\image-20200415131055981.png)

tail -f logs/esearch.log|grep -v watcher|grep -v dispatcher|grep '格式'|awk '{print $8}'





sed -i 's/size=35&/size=300&/g' `grep frequency_desc  -rl condition.txt_10%`





最大能65*120=7800， 我们确认下线上redis 设置的连接数

1. 创建线程获取redis数据时间有部分耗时会到达80ms左右，出现的时间隔  大约是2分钟一次，每次大约10几个请求. 不知道原因是啥

2.  当前线程池大小是8，将连接释放 在锁内，redis连接数是65， 将连接释放 放到锁外， redis连接数变为17，这个现象的问题是 不知道 为什么是redis连接数是17

   